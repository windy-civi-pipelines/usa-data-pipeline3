<?xml version="1.0"?>
<?xml-stylesheet type="text/xsl" href="billres.xsl"?>
<!DOCTYPE bill PUBLIC "-//US Congress//DTDs/bill.dtd//EN" "bill.dtd">
<bill bill-stage="Introduced-in-Senate" dms-id="A1" public-private="public" slc-id="S1-ELT25909-6MF-78-T4S">
    <metadata xmlns:dc="http://purl.org/dc/elements/1.1/">
<dublinCore>
<dc:title>119 S2938 IS: Artificial Intelligence Risk Evaluation Act of 2025</dc:title>
<dc:publisher>U.S. Senate</dc:publisher>
<dc:date>2025-09-29</dc:date>
<dc:format>text/xml</dc:format>
<dc:language>EN</dc:language>
<dc:rights>Pursuant to Title 17 Section 105 of the United States Code, this file is not subject to copyright protection and is in the public domain.</dc:rights>
</dublinCore>
</metadata>
<form>
        <distribution-code>II</distribution-code>
        <congress>119th CONGRESS</congress>
        <session>1st Session</session>
        <legis-num>S. 2938</legis-num>
        <current-chamber>IN THE SENATE OF THE UNITED STATES</current-chamber>
        <action>
            <action-date date="20250929">September 29, 2025</action-date>
            <action-desc><sponsor name-id="S399">Mr. Hawley</sponsor> (for himself and <cosponsor name-id="S341">Mr. Blumenthal</cosponsor>) introduced the following bill; which
                was read twice and referred to the <committee-name committee-id="SSCM00">Committee
                    on Commerce, Science, and Transportation</committee-name></action-desc>
        </action>
        <legis-type>A BILL</legis-type>
        <official-title>To require the Secretary of Energy to establish the Advanced Artificial
            Intelligence Evaluation Program, and for other purposes.</official-title>
    </form>
    <legis-body>
        <section id="S1" section-type="section-one">
            <enum>1.</enum>
            <header>Short title</header>
 <text display-inline="no-display-inline">This Act may be cited as the <quote><short-title>Artificial Intelligence Risk Evaluation Act of 2025</short-title></quote>.</text>
        </section>
        <section id="id6314c140dde846e897637a096a870e9e" commented="no">
            <enum>2.</enum>
            <header>Sense of Congress; purposes</header>
            <subsection id="idde91a627bae24df4aaa77188e2079414">
                <enum>(a)</enum>
                <header>Sense of Congress</header>
 <text>It is the sense of Congress that rapidly advancing artificial intelligence capabilities present both opportunities and significant risks to national security, public safety, economic competitiveness, civil liberties, and healthy labor and other markets, and that, as artificial intelligence advances toward human-level capabilities in virtually all domains, the United States must establish a secure testing and evaluation program to generate data-driven options for managing emerging risks.</text>
            </subsection>
            <subsection id="idd64eef6523514935b03b307dd21a2b2c">
                <enum>(b)</enum>
                <header>Purposes</header>
 <text>The purposes of the program established under this Act are to provide Congress with the empirical data, lessons, and insights necessary for Federal oversight of artificial intelligence to ensure that regulatory decisions are made on the basis of empirical testing, and to enable Congress to safeguard American citizens.</text>
            </subsection>
        </section>
        <section id="ideb8ae9d28d284623ac5cd435a25c421e">
            <enum>3.</enum>
            <header>Definitions</header>
 <text display-inline="no-display-inline">In this Act:</text> <paragraph id="id7160f99632b047aba2dc996d56b2988d"> <enum>(1)</enum> <header>Advanced artificial intelligence system</header> <subparagraph commented="no" display-inline="no-display-inline" id="idfc5fd8ddb7784915a285503b9293fe89"> <enum>(A)</enum> <header>In general</header> <text display-inline="yes-display-inline">Subject to subparagraph (B), the term <term>advanced artificial intelligence system</term> means an artificial intelligence system that was trained using a quantity of computing power greater than 10<superscript>26</superscript> integer or floating-point operations.</text>
                </subparagraph>
                <subparagraph id="id54dda4fa66694b9bb3495ad87e70ef60" commented="no">
                    <enum>(B)</enum>
                    <header>Alternate meaning</header>
 <text>The Secretary may, by a rule, propose a new definition of the term <term>advanced artificial intelligence system</term> to replace the definition in subparagraph (A), which new definition shall not go into effect until the Secretary submits the rule to Congress and a joint resolution approving the rule is enacted into law.</text>
                </subparagraph>
            </paragraph>
            <paragraph id="idbf6eac9377634b66b85d25599d4398e2">
                <enum>(2)</enum>
                <header>Adverse <enum-in-header>AI</enum-in-header> incident</header>
 <text>The term <term>adverse AI incident</term> means an incident relating to an artificial intelligence system that involves—</text>
                <subparagraph id="idcbccff66f8ec4f6bb2a160f6b1f87c7f">
                    <enum>(A)</enum>
 <text>a loss-of-control scenario;</text> </subparagraph> <subparagraph id="ide2fb06ed56be46f79652b8faf74fcc29"> <enum>(B)</enum> <text>a risk of weaponization by a foreign adversary, a foreign terrorist organization, or another adversary of the United States Government;</text>
                </subparagraph>
                <subparagraph id="id82b71e4ae0a549dd98c26b909313088d">
                    <enum>(C)</enum>
 <text>a threat to the safety or reliability of critical infrastructure (as defined in subsection (e) of the Critical Infrastructures Protection Act of 2001 (<external-xref legal-doc="usc" parsable-cite="usc/42/5195c">42 U.S.C. 5195c(e)</external-xref>));</text>
                </subparagraph>
                <subparagraph id="idcb31eb8f16ef429dbed44362f6f5811d">
                    <enum>(D)</enum>
 <text>a significant erosion of civil liberties, economic competition, and healthy labor markets;</text>
                </subparagraph>
                <subparagraph id="id68573401737145ff8fb2dc665b6be125">
                    <enum>(E)</enum>
 <text>scheming behavior; or</text> </subparagraph> <subparagraph id="id6e265d3bc35c447d872e99c3555ee33c"> <enum>(F)</enum> <text>an attempt to carry out an incident described in subparagraphs (A) through (E).</text>
                </subparagraph>
            </paragraph>
            <paragraph id="idc54fd07f91c14420afee6619e9011211">
                <enum>(3)</enum>
                <header>Artificial intelligence; <enum-in-header>AI</enum-in-header></header>
 <text>The term <term>artificial intelligence</term> or <term>AI</term> means technology that enables a device or software—</text>
                <subparagraph commented="no" display-inline="no-display-inline" id="id46ade64cd67849ca9e90910618bc745e">
                    <enum>(A)</enum>
 <text display-inline="yes-display-inline">to make—for a given set of human-defined objectives—predictions, recommendations, or decisions influencing real or virtual environments; and</text>
                </subparagraph>
                <subparagraph commented="no" display-inline="no-display-inline" id="idfdc2a0b13fcf4c6eb79e262d94f2655a">
                    <enum>(B)</enum>
 <text display-inline="yes-display-inline">to use machine and human-based inputs—</text>
                    <clause id="idb9f20c3a265c46f6a14111f0dd5e244d">
                        <enum>(i)</enum>
 <text>to perceive real and virtual environments;</text> </clause> <clause id="id444aa96f8e614a2ca20f810c9c0286b9"> <enum>(ii)</enum> <text>to abstract such perceptions into models through analysis in an automated manner; and</text>
                    </clause>
                    <clause id="id8f94e980ab64431689848ba8ba081a94">
                        <enum>(iii)</enum>
 <text>to use model inference to formulate options for information or action.</text>
                    </clause>
                </subparagraph>
            </paragraph>
            <paragraph commented="no" display-inline="no-display-inline" id="id5a42ec785a5646c4b16c350b4226626c">
                <enum>(4)</enum>
                <header display-inline="yes-display-inline">Artificial intelligence system;
                        <enum-in-header>AI</enum-in-header> system</header>
 <text>The term <term>artificial intelligence system</term> or <term>AI system</term> means a particular model, program, or tool within the field of artificial intelligence.</text>
            </paragraph>
            <paragraph id="idd97d6dd70bd24266b2acbbe3bfede92e">
                <enum>(5)</enum>
                <header>Artificial superintelligence</header>
                <subparagraph commented="no" display-inline="no-display-inline" id="idd862ae506d2343099c63fd2c683c99ae">
                    <enum>(A)</enum>
                    <header>In general</header>
 <text display-inline="yes-display-inline">The term <term>artificial superintelligence</term> means artificial intelligence that exhibits, or can easily be modified to exhibit, all of the characteristics described in subparagraph (B).</text>
                </subparagraph>
                <subparagraph commented="no" display-inline="no-display-inline" id="id2f5da1e5971944c19e3018ab0a719608">
                    <enum>(B)</enum>
                    <header>Characteristics described</header>
 <text>The characteristics referred to in subparagraph (A) are the following:</text>
                    <clause id="idd778bd66edd64cf08a73bd1999cf5904">
                        <enum>(i)</enum>
 <text>The AI can enable a device or software to operate autonomously and effectively for long stretches of time in open-ended environments and in pursuit of broad objectives.</text>
                    </clause>
                    <clause id="id932e5d0ac1ef46b0b7abcffe8592b2e1">
                        <enum>(ii)</enum>
 <text>The AI can enable a device or software to match or exceed human cognitive performance and capabilities across most domains or tasks, including those related to decisionmaking, learning, and adaptive behaviors.</text>
                    </clause>
                    <clause id="id18210ff70d674d929332c49a81aee772">
                        <enum>(iii)</enum>
 <text>The AI can enable a device or software to potentially exhibit the capacity to independently modify or enhance its own functions in ways that could plausibly circumvent human control or oversight, posing substantial and unprecedented risks to humanity.</text>
                    </clause>
                </subparagraph>
            </paragraph>
            <paragraph id="id7f63a1e6a91042ce9b1a591a77c25e9d">
                <enum>(6)</enum>
                <header>Computing power</header>
 <text>The term <term>computing power</term> means the processing power and other electronic resources used to train, validate, deploy, and run AI algorithms and models.</text>
            </paragraph>
            <paragraph id="idf3007d3df55c415b8f3a1fb2df824f22" commented="no">
                <enum>(7)</enum>
                <header>Covered advanced artificial intelligence system developer</header>
 <text>The term <term>covered advanced artificial intelligence system developer</term> means a person that designs, codes, produces, owns, or substantially modifies an advanced artificial intelligence system for use in interstate or foreign commerce, including by taking steps to initiate a training run of the advanced artificial intelligence system.</text>
            </paragraph>
            <paragraph id="ida8b82db41b064c2da31a28b9c9913e59">
                <enum>(8)</enum>
                <header>Deploy</header>
 <text>The term <term>deploy</term> means an action taken by a covered advanced artificial intelligence system developer to release, sell, or otherwise provide access to an advanced artificial intelligence system outside the custody of the developer, including by releasing an open-source advanced artificial intelligence system.</text>
            </paragraph>
            <paragraph id="idad39e7820ed049bda8e140f07ba68bb5">
                <enum>(9)</enum>
                <header>Foreign adversary</header>
 <text>The term <term>foreign adversary</term> means a foreign adversary (as defined in section 791.2 of title 15, Code of Federal Regulations) (or successor regulations) that is included on the list in section 791.4(a) of that title (or successor regulations).</text>
            </paragraph>
            <paragraph id="id87808548e1f54cc5b809bacc4409bb04">
                <enum>(10)</enum>
                <header>Foreign terrorist organization</header>
 <text>The term <term>foreign terrorist organization</term> means a foreign entity designated as a foreign terrorist organization by the Secretary of State under section 219 of the Immigration and Nationality Act (<external-xref legal-doc="usc" parsable-cite="usc/8/1189">8 U.S.C. 1189</external-xref>).</text>
            </paragraph>
            <paragraph id="idb5079f7eae3b4d1eb8170058d325c6ba">
                <enum>(11)</enum>
                <header>Interstate or foreign commerce</header>
 <text>The term <term>interstate or foreign commerce</term> has the meaning given the term in section 921(a) of title 18, United States Code.</text>
            </paragraph>
            <paragraph id="idf86d42e0493945e2bc02bfc9151654f7">
                <enum>(12)</enum>
                <header>Loss-of-control scenario</header>
 <text>The term <term>loss-of-control scenario</term> means a scenario in which an artificial intelligence system—</text>
                <subparagraph id="id76710fb85f4047f2b45d4fc75ee40925">
                    <enum>(A)</enum>
 <text>behaves contrary to its instruction or programming by human designers or operators;</text>
                </subparagraph>
                <subparagraph id="id4f001f91aefe40ea92b90b35e18ce942">
                    <enum>(B)</enum>
 <text>deviates from rules established by human designers or operators;</text> </subparagraph> <subparagraph id="idde965ece17a6479b9ce2efa54ff666ea"> <enum>(C)</enum> <text>alters operational rules or safety constraints without authorization;</text>
                </subparagraph>
                <subparagraph id="id596866e6337c415a8fd6dcc91e63b3a3">
                    <enum>(D)</enum>
 <text>operates beyond the scope intended by human designers or operators;</text> </subparagraph> <subparagraph id="idb1c3a595f5954a6ab37725207194540f"> <enum>(E)</enum> <text>pursues goals that are different from those intended by human designers or operators;</text>
                </subparagraph>
                <subparagraph id="id2780559dfc704869a39ca450e79892fc">
                    <enum>(F)</enum>
 <text>subverts oversight or shutdown mechanisms; or</text> </subparagraph> <subparagraph id="id81b6186a8fd04b6cba705c3738ce6401"> <enum>(G)</enum> <text>otherwise behaves in an unpredictable manner so as to be harmful to humanity.</text>
                </subparagraph>
            </paragraph>
            <paragraph commented="no" display-inline="no-display-inline" id="id9ee93f38ad8841d3ae1fba2c45131dae">
                <enum>(13)</enum>
                <header>Program</header>
 <text>The term <quote>program</quote> means the Advanced Artificial Intelligence Evaluation Program established under section 5.</text>
            </paragraph>
            <paragraph id="id07f0cbe183ee42a1a22fded616b5454a">
                <enum>(14)</enum>
                <header>Scheming behavior</header>
 <text>The term <term>scheming behavior</term> means behavior by an AI system to deceive human designers or operators, including by—</text>
                <subparagraph commented="no" display-inline="no-display-inline" id="id66f1f80ada3d4ac8a13d41463aa2b64e">
                    <enum>(A)</enum>
 <text display-inline="yes-display-inline">hiding its true capabilities and objectives; or</text>
                </subparagraph>
                <subparagraph commented="no" display-inline="no-display-inline" id="id023b07e6be51499d91d80ac446c033cf">
                    <enum>(B)</enum>
 <text display-inline="yes-display-inline">attempting to subvert oversight mechanisms or shutdown mechanisms.</text>
                </subparagraph>
            </paragraph>
            <paragraph id="id74bb45783f9d4843b911e9644bb0ab7e">
                <enum>(15)</enum>
                <header>Secretary</header>
 <text>The term <quote>Secretary</quote> means the Secretary of Energy.</text> </paragraph> </section> <section id="id45c506f312c049218dc9bcf584d6d8e6"> <enum>4.</enum> <header>Obligation to participate; enforcement and penalties</header> <subsection id="ide058c5ea009f4785be30c1f26267d5db"> <enum>(a)</enum> <header>In general</header> <text>Each covered advanced artificial intelligence system developer shall—</text>
                <paragraph commented="no" display-inline="no-display-inline" id="idfc034b4df21c4e52ba21d4a83699107f">
                    <enum>(1)</enum>
 <text display-inline="yes-display-inline">participate in the program; and</text> </paragraph> <paragraph commented="no" display-inline="no-display-inline" id="id97037a5732664370a1645370e9d50b0b"> <enum>(2)</enum> <text display-inline="yes-display-inline">provide to the Secretary, on request, materials and information necessary to carry out the program, which may include, with respect to the advanced artificial intelligence system of the covered advanced artificial intelligence system developer—</text>
                    <subparagraph id="idfdf275898fce460884d0051157abc683">
                        <enum>(A)</enum>
 <text>the underlying code of the advanced artificial intelligence system;</text>
                    </subparagraph>
                    <subparagraph id="idac06613160f442ce93246d72039bbda7">
                        <enum>(B)</enum>
 <text>data used to train the advanced artificial intelligence system;</text> </subparagraph> <subparagraph id="id92ad78db52d1411dbeec49b27263c1ab"> <enum>(C)</enum> <text>model weights or other adjustable parameters for the advanced artificial intelligence system;</text>
                    </subparagraph>
                    <subparagraph id="idf24bf017e5964730948ad44a6eabd662">
                        <enum>(D)</enum>
 <text>the interface engine or other implementation of the advanced artificial intelligence system; and</text>
                    </subparagraph>
                    <subparagraph id="id5399f6bed3d549d0b8a6a6c589d1d6f4">
                        <enum>(E)</enum>
 <text>detailed information regarding the training, model architecture, or other aspects of the advanced artificial intelligence system.</text>
                    </subparagraph>
                </paragraph>
            </subsection>
            <subsection id="iddf4add1bb888419c9b08e4cd0f205b32">
                <enum>(b)</enum>
                <header>Prohibition on deployment</header>
 <text>No person may deploy an advanced artificial intelligence system for use in interstate or foreign commerce unless that person is in compliance with subsection (a).</text>
            </subsection>
            <subsection id="idabef02e00927466388cbfd7a8c484d48">
                <enum>(c)</enum>
                <header>Penalty</header>
 <text>A person that violates subsection (a) or (b) shall be fined not less than $1,000,000 per day of the violation.</text>
            </subsection>
        </section>
        <section id="id468c9d2b17934dfdbb0c92a564ae994e">
            <enum>5.</enum>
            <header>Advanced Artificial Intelligence Evaluation Program</header>
            <subsection id="ide9c90a53c07843f2ae210f2b15ff6978">
                <enum>(a)</enum>
                <header>In general</header>
 <text>Not later than 90 days after the date of enactment of this Act, the Secretary shall establish an Advanced Artificial Intelligence Evaluation Program within the Department of Energy.</text>
            </subsection>
            <subsection id="ide9b0330a78494d93b1512797a44e3690">
                <enum>(b)</enum>
                <header>Activities</header>
 <text>The program shall—</text> <paragraph id="id943db74a841944adbd6e574164b7562d"> <enum>(1)</enum> <text>offer standardized and classified testing and evaluation of advanced AI systems to systematically collect data on the likelihood of adverse AI incidents for a given advanced AI system;</text>
                </paragraph>
                <paragraph id="id1f44b252a6d34131b86389af8f5aa095">
                    <enum>(2)</enum>
 <text>implement testing protocols that match or exceed anticipated real-world AI jailbreaking techniques, including adversarial testing by red teams with expertise comparable to sophisticated malicious actors;</text>
                </paragraph>
                <paragraph id="id05dae56e80564f97b816e5153601ac88">
                    <enum>(3)</enum>
 <text>to the extent feasible, establish and facilitate classified, independent third-party assessments and blind model evaluations to maintain transparency and reliability;</text>
                </paragraph>
                <paragraph id="ida7b1e7f8d1644476b254b06d1c64bcee">
                    <enum>(4)</enum>
 <text>provide participating entities with a formal report based on testing outcomes that clearly identifies evaluated risks and safety measures;</text>
                </paragraph>
                <paragraph id="id7698f0f514b844d9adeb78a3a0f2138d">
                    <enum>(5)</enum>
 <text>develop recommended containment protocols, contingency planning, and mitigation strategies informed by testing data to address identified risks;</text>
                </paragraph>
                <paragraph id="id2d2a9940bad64f1bb55be659e2c0f70c">
                    <enum>(6)</enum>
 <text>inform the creation of evidence-based standards, regulatory options, guidelines, and governance mechanisms based on data collected from testing and evaluations;</text>
                </paragraph>
                <paragraph id="idd2eb43ffb4084f4b87a34e6f19e553b3">
                    <enum>(7)</enum>
 <text>assist Congress in determining the potential for controlled AI systems to reach artificial superintelligence, exceed human oversight or operational control, or pose existential threats to humanity by providing comprehensive empirical evaluations and risk assessments; and</text>
                </paragraph>
                <paragraph id="id495ba9404df94c4c91ffd0b04626553a">
                    <enum>(8)</enum>
 <text>develop proposed options for regulatory or governmental oversight, including potential nationalization or other strategic measures, for preventing or managing the development of artificial superintelligence if artificial superintelligence seems likely to arise.</text>
                </paragraph>
            </subsection>
            <subsection id="id5cab0be336c848f89158032a0300f54d">
                <enum>(c)</enum>
                <header>Plan for permanent framework</header>
                <paragraph id="id18f6cb93845e41f583c0d043b95aa8ab">
                    <enum>(1)</enum>
                    <header>In general</header>
 <text>Not later than 360 days after the date of enactment of this Act, the Secretary shall submit to Congress a detailed recommendation for Federal oversight of advanced artificial intelligence systems, drawing directly upon insights, empirical data, and lessons learned from the program.</text>
                </paragraph>
                <paragraph commented="no" display-inline="no-display-inline" id="id2fb8ba425d4248a39bbd9949c8ba57a5">
                    <enum>(2)</enum>
                    <header>Contents</header>
 <text display-inline="yes-display-inline">The plan submitted under paragraph (1) shall—</text>
                    <subparagraph id="idf14f250d8db64b4a8f2432dc317dbdd7">
                        <enum>(A)</enum>
 <text>summarize and analyze outcomes from testing, identifying key trends, capabilities, potential risks, and system behaviors such as weaponization potential, self-replication capabilities, scheming behaviors, autonomous decisionmaking, and automated AI development capabilities;</text>
                    </subparagraph>
                    <subparagraph id="idaac22ad3d5d84ab38fe950fb11600528">
                        <enum>(B)</enum>
 <text>recommend evidence-based standards, certification procedures, licensing requirements, and regulatory oversight structures specifically informed by testing and evaluation data, ensuring alignment between identified risks and regulatory responses;</text>
                    </subparagraph>
                    <subparagraph id="iddb3fa0109d854b1a87b80fc78ebe48ab">
                        <enum>(C)</enum>
 <text>outline proposals for automated and continuous monitoring of AI hardware usage, computational resource inputs, and cloud-computing deployments based on observed relationships between those factors and AI system performance or emergent capabilities;</text>
                    </subparagraph>
                    <subparagraph id="id7555f7b2c9bb4634932cf712383c5fa0">
                        <enum>(D)</enum>
 <text>propose adaptive governance strategies that account for ongoing improvements in algorithmic efficiency and system capabilities, ensuring that regulatory frameworks remain relevant and effective as AI technology advances;</text>
                    </subparagraph>
                    <subparagraph id="idcb6fcad862224318a6a023deca185010">
                        <enum>(E)</enum>
 <text>suggest revisions with respect to Federal oversight or resourcing, such as a new office within an existing agency, a new agency, or additional funding, that may be necessary to develop and administer a permanent framework for oversight of advanced artificial intelligence systems; and</text>
                    </subparagraph>
                    <subparagraph id="idfc12d8e37e77464eb6406868df138ed9">
                        <enum>(F)</enum>
 <text>provide comprehensive evaluations regarding the potential for tested AI systems to exceed human oversight, approach artificial superintelligence, threaten economic competition (including in labor markets), undermine civil liberties, and pose existential risks to humanity, including clearly articulated options for regulatory or governmental oversight measures to address scenarios of imminent concern identified through testing.</text>
                    </subparagraph>
                </paragraph>
                <paragraph id="id0642995d7616481f8a1300ce6ff870b1">
                    <enum>(3)</enum>
                    <header>Updates</header>
 <text>Not less frequently than once every year for the duration of the program, the Secretary shall—</text>
                    <subparagraph commented="no" display-inline="no-display-inline" id="idf75fdd0facb44b61ab7c800707e53093">
                        <enum>(A)</enum>
 <text display-inline="yes-display-inline">update the plan submitted under paragraph (1) with new insights, data, and lessons from the program; and</text>
                    </subparagraph>
                    <subparagraph commented="no" display-inline="no-display-inline" id="id6838f0bda11348abacc4a1072459ad50">
                        <enum>(B)</enum>
 <text display-inline="yes-display-inline">submit the updated plan to Congress.</text>
                    </subparagraph>
                </paragraph>
            </subsection>
            <subsection id="id4e21b9165c654f3b84b0ebe16509bfca">
                <enum>(d)</enum>
                <header>Sunset</header>
 <text>The program shall terminate on the date that is 7 years after the date of enactment of this Act, unless renewed by Congress.</text>
            </subsection>
        </section>
    </legis-body>
</bill>

