<?xml version="1.0"?>
<?xml-stylesheet type="text/xsl" href="billres.xsl"?>
<!DOCTYPE bill PUBLIC "-//US Congress//DTDs/bill.dtd//EN" "bill.dtd">
<bill bill-stage="Introduced-in-House" dms-id="H461618E6A2A143AA9C297AC94DC1FC99" public-private="public" key="H" bill-type="olc"><metadata xmlns:dc="http://purl.org/dc/elements/1.1/">
<dublinCore>
<dc:title>119 HR 3919 IH: Advanced AI Security Readiness Act</dc:title>
<dc:publisher>U.S. House of Representatives</dc:publisher>
<dc:date>2025-06-11</dc:date>
<dc:format>text/xml</dc:format>
<dc:language>EN</dc:language>
<dc:rights>Pursuant to Title 17 Section 105 of the United States Code, this file is not subject to copyright protection and is in the public domain.</dc:rights>
</dublinCore>
</metadata>
<form>
<distribution-code display="yes">I</distribution-code><congress display="yes">119th CONGRESS</congress><session display="yes">1st Session</session><legis-num display="yes">H. R. 3919</legis-num><current-chamber>IN THE HOUSE OF REPRESENTATIVES</current-chamber><action display="yes"><action-date date="20250611">June 11, 2025</action-date><action-desc><sponsor name-id="L000585">Mr. LaHood</sponsor> (for himself, <cosponsor name-id="M001194">Mr. Moolenaar</cosponsor>, <cosponsor name-id="G000583">Mr. Gottheimer</cosponsor>, and <cosponsor name-id="K000391">Mr. Krishnamoorthi</cosponsor>) introduced the following bill; which was referred to the <committee-name committee-id="HIG00">Permanent Select Committee on Intelligence</committee-name></action-desc></action><legis-type>A BILL</legis-type><official-title display="yes">To direct the Director of the National Security Agency to develop strategies to secure artificial intelligence related technologies.</official-title></form><legis-body id="H5CD26EE6E643449AA4D2B2C49A2F982C" style="OLC"> 
<section id="HB36868DDBAD6438182E351A5E0E49E15" section-type="section-one"><enum>1.</enum><header>Short title</header><text display-inline="no-display-inline">This Act may be cited as the <quote><short-title>Advanced AI Security Readiness Act</short-title></quote>.</text></section> <section id="H7B3B889060014D1BBD4733D93170772A" section-type="subsequent-section"><enum>2.</enum><header>AI security playbook</header> <subsection id="HE58B615224F74A0E9A2A3CFCE84C1022"><enum>(a)</enum><header>Requirement</header><text display-inline="yes-display-inline">The Director of the National Security Agency, acting through the Artificial Intelligence Security Center (or successor office), shall develop strategies (in this section referred to as the <quote>AI Security Playbook</quote>) to defend covered AI technologies from technology theft by threat actors.</text> </subsection> 
<subsection id="H3B831DCF4B1E4D58BB40B78EBFD5D1FC"><enum>(b)</enum><header>Elements</header><text display-inline="yes-display-inline">The AI Security Playbook under subsection (a) shall include the following:</text> <paragraph id="H744C8CD549014D7FBACC34C973467FD5"><enum>(1)</enum><text display-inline="yes-display-inline">Identification of potential vulnerabilities in advanced AI data centers and among advanced AI developers capable of producing covered AI technologies, with a focus on cybersecurity risks and other security challenges that are unique to protecting covered AI technologies and critical components of such technologies (such as threat vectors that do not typically arise, or are less severe, in the context of conventional information technology systems).</text></paragraph> 
<paragraph id="H354960EE6F7444E2886A8B6CBDEC9950"><enum>(2)</enum><text display-inline="yes-display-inline">Identification of components or information that, if accessed by threat actors, would meaningfully contribute to progress made by the actor with respect to developing covered AI technologies, including with respect to—</text> <subparagraph id="H81F9308C25744F439CDF3F55B7D53252"><enum>(A)</enum><text>AI models and key components of such models;</text></subparagraph> 
<subparagraph id="H7163D8F33A4A43B28708E750B4FFCCCB"><enum>(B)</enum><text>core insights relating to the development of advanced AI systems, including with respect to training such systems, the inferences made by such systems, and the engineering of such systems; and</text></subparagraph> <subparagraph id="H6EC3CA2F291546E6B96B30893FFD82F9"><enum>(C)</enum><text>other related information.</text></subparagraph></paragraph> 
<paragraph id="H259C2D85B737452CB6A678A667FAB80B"><enum>(3)</enum><text display-inline="yes-display-inline">Strategies to detect, prevent, and respond to cyber threats by threat actors targeting covered AI technologies.</text></paragraph> <paragraph id="HB5E08EF6F8DF4A29A25E0AE381B61A2C"><enum>(4)</enum><text display-inline="yes-display-inline">Identification of the levels of security, if any, that would require substantial involvement by the United States Government in the development or oversight of highly advanced AI systems.</text></paragraph> 
<paragraph id="H2BD6EF307C5545529A80AE88558343E0"><enum>(5)</enum><text display-inline="yes-display-inline">Analysis of how the United States Government would be involved to achieve the levels of security identified in paragraph (4), including a description of a hypothetical initiative to build covered AI technology systems in a highly secure governmental environment, considering, at a minimum, cybersecurity protocols, provisions to protect model weights, efforts to mitigate insider threats (including personnel vetting and security clearance adjudication processes), access control procedures, counterintelligence and anti-espionage measures, contingency and emergency response plans, and other strategies that would be used to reduce threats of technology theft by threat actors.</text></paragraph></subsection> <subsection id="H598FAA0D340647CEA15797E4E088AB6F"><enum>(c)</enum><header>Form</header><text display-inline="yes-display-inline">The AI Security Playbook under subsection (a) shall include—</text> 
<paragraph id="H57604BBF28184B8499952A63A5F07216"><enum>(1)</enum><text>detailed methodologies and intelligence assessments, which may be contained in a classified annex; and</text></paragraph> <paragraph id="H70C4F2A8FA0D42E89178782FE1334763"><enum>(2)</enum><text>an unclassified portion with general guidelines and best practices suitable for dissemination to relevant individuals, including in the private sector.</text></paragraph></subsection> 
<subsection id="H445E66CF25FA4B26BC1502C06AC28C61"><enum>(d)</enum><header>Engagement</header> 
<paragraph id="H29049122B8F04F4783995170407DDD7C"><enum>(1)</enum><header>In general</header><text>In developing the AI Security Playbook under subsection (a), the Director shall—</text> <subparagraph id="H6C4DCF325B8242479E5AC993615D62B3"><enum>(A)</enum><text display-inline="yes-display-inline">engage with prominent AI developers and researchers, as determined by the Director, to assess and anticipate the capabilities of highly advanced AI systems relevant to national security, including by—</text> 
<clause id="H2BBAAF53A5B145E9A167511C06B1D631"><enum>(i)</enum><text>conducting a comprehensive review of industry documents pertaining to the security of AI systems with respect to preparedness frameworks, scaling policies, risk management frameworks, and other matters;</text></clause> <clause id="H850385E0A5A042E885DDC1F81AACC7EC"><enum>(ii)</enum><text>conducting interviews with subject matter experts;</text></clause> 
<clause id="H0EBC0D52455542C8BE3AD8EB120B2099"><enum>(iii)</enum><text>hosting roundtable discussions and expert panels; and</text></clause> <clause id="H06B1C805023D4390BFABE789B2ED3741"><enum>(iv)</enum><text>visiting facilities used to develop AI; and</text></clause></subparagraph> 
<subparagraph id="HB723095DA22A4E068009BA83998F70E5"><enum>(B)</enum><text display-inline="yes-display-inline">to leverage existing expertise and research, collaborate with a federally funded research and development center that has conducted research on strategies to secure AI models from nation-state actors and other highly resourced actors.</text></subparagraph></paragraph> <paragraph id="H1D4D42777770429F9BEC502E5D2A8648"><enum>(2)</enum><header>Nonapplicability of FACA</header><text display-inline="yes-display-inline">None of the activities described in this subsection shall be construed to establish or use an advisory committee subject to <external-xref legal-doc="usc-chapter" parsable-cite="usc-chapter/5/10">chapter 10</external-xref> of title 5, United States Code.</text></paragraph></subsection> 
<subsection id="H4FDD53F27AFE409F8B38398482E52E34"><enum>(e)</enum><header>Reports</header> 
<paragraph id="H26E0586030AE49D8967501CAE4ADF86C"><enum>(1)</enum><header>Initial report</header><text display-inline="yes-display-inline">Not later than 90 days after the date of the enactment of this Act, the Director shall submit to the appropriate congressional committees a report on the AI Security Playbook under subsection (a), including a summary of progress on the development of Playbook, an outline of remaining sections, and any relevant insights about AI security.</text> </paragraph> <paragraph id="H5619A7B6A5CC46F7A9FEEFDA69D97CC8"><enum>(2)</enum><header>Final report</header><text display-inline="yes-display-inline">Not later than 270 days after the date of enactment of this Act, the Director shall submit to the appropriate congressional committees a report on the Playbook.</text></paragraph> 
<paragraph id="HE015788A06D044F2A20BDF27DD2920E5"><enum>(3)</enum><header>Form</header><text>The report submitted under paragraph (2)—</text> <subparagraph id="H37ED09D49FF7459C9F905976275BA825"><enum>(A)</enum><text display-inline="yes-display-inline">shall include—</text> 
<clause id="HE9FBEDB4727642CF917B440EBC9E99B2"><enum>(i)</enum><text>an unclassified version suitable for dissemination to relevant individuals, including in the private sector; and</text></clause> <clause id="H6D00372D896846B798A3FF19A6A6EBCF"><enum>(ii)</enum><text>a publicly available version; and</text></clause></subparagraph> 
<subparagraph id="H4D9E6378B5804DBCAC5F1262E067CA4E"><enum>(B)</enum><text>may include a classified annex.</text></subparagraph></paragraph></subsection> <subsection id="HACD7DFC350084BEDB30A9412D6268D82"><enum>(f)</enum><header>Rule of construction</header><text display-inline="yes-display-inline">Nothing in subsection (b)(4) shall be construed to authorize or require any regulatory or enforcement action by the United States Government.</text></subsection> 
<subsection id="H52ADC870C90144788914D126ADED773A"><enum>(g)</enum><header>Definitions</header><text>In this section:</text> <paragraph id="H63050519E0AD45348F01EFA47DE682D4"><enum>(1)</enum><text display-inline="yes-display-inline">The term <term>appropriate congressional committees</term> means the Permanent Select Committee on Intelligence of the House of Representatives and the Select Committee on Intelligence of the Senate.</text> </paragraph> 
<paragraph id="HA3D4924C0F9D47B1993B8F5BAD1F0E6F"><enum>(2)</enum><text>The terms <term>artificial intelligence</term> and <term>AI</term> have the meaning given the term <term>artificial intelligence</term> in section 238(g) of the John S. McCain National Defense Authorization Act for Fiscal Year 2019 (<external-xref legal-doc="public-law" parsable-cite="pl/115/232">Public Law 115–232</external-xref>; 10 U.S.C. note prec. 4061).</text></paragraph> <paragraph id="H075ABF1DDE7A4C90829D85F67E542778"><enum>(3)</enum><text display-inline="yes-display-inline">The term <term>covered AI technologies</term> means advanced AI (whether developed by the private sector, the United States Government, or a public-private partnership) with critical capabilities that the Director determines would pose a grave national security threat if acquired or stolen by threat actors, such as AI systems that match or exceed human expert performance in relating to chemical, biological, radiological, and nuclear matters, cyber offense, model autonomy, persuasion, research and development, and self-improvement.</text> </paragraph> 
<paragraph id="H6C9E7EE5AD2E4213961F53BA291AD530"><enum>(4)</enum><text display-inline="yes-display-inline">The term <term>technology theft</term> means any unauthorized acquisition, replication, or appropriation of covered AI technologies or components of such technologies, including models, model weights, architectures, or core algorithmic insights, through any means, such as cyber attacks, insider threats, and side-channel attacks, or exploitation of public interfaces.</text></paragraph> <paragraph id="H0F6EF632B9294CE28AAC7AEDCF90ACA2"><enum>(5)</enum><text display-inline="yes-display-inline">The term <term>threat actors</term> means nation-state actors and other highly resourced actors capable of technology theft.</text> </paragraph></subsection></section> 
</legis-body></bill>

