<?xml version="1.0"?>
<?xml-stylesheet type="text/xsl" href="billres.xsl"?>
<!DOCTYPE bill PUBLIC "-//US Congress//DTDs/bill.dtd//EN" "bill.dtd">
<bill bill-stage="Introduced-in-Senate" dms-id="A1" public-private="public" slc-id="S1-ALL25603-6LJ-4P-NCW"><metadata xmlns:dc="http://purl.org/dc/elements/1.1/">
<dublinCore>
<dc:title>119 S2081 IS: Responsible Innovation and Safe Expertise Act of 2025</dc:title>
<dc:publisher>U.S. Senate</dc:publisher>
<dc:date>2025-06-12</dc:date>
<dc:format>text/xml</dc:format>
<dc:language>EN</dc:language>
<dc:rights>Pursuant to Title 17 Section 105 of the United States Code, this file is not subject to copyright protection and is in the public domain.</dc:rights>
</dublinCore>
</metadata>
<form>
<distribution-code display="yes">II</distribution-code><congress>119th CONGRESS</congress><session>1st Session</session><legis-num>S. 2081</legis-num><current-chamber>IN THE SENATE OF THE UNITED STATES</current-chamber><action><action-date date="20250612">June 12, 2025</action-date><action-desc><sponsor name-id="S410">Ms. Lummis</sponsor> introduced the following bill; which was read twice and referred to the <committee-name committee-id="SSCM00">Committee on Commerce, Science, and Transportation</committee-name></action-desc></action><legis-type>A BILL</legis-type><official-title>To establish immunity from civil liability for certain artificial intelligence developers, and for other purposes.</official-title></form><legis-body><section id="S1" section-type="section-one"><enum>1.</enum><header>Short title</header><text display-inline="no-display-inline">This Act may be cited as the <quote><short-title>Responsible Innovation and Safe Expertise Act of 2025</short-title></quote> or the <quote><short-title>RISE Act of 2025</short-title></quote>.</text></section><section commented="no" display-inline="no-display-inline" id="id91becfab3bef47c3bd816cc6694b3b50"><enum>2.</enum><header>Findings</header><text display-inline="no-display-inline">Congress finds the following:</text><paragraph id="id6177fd9e84174e919b487b6f7e9eb6e8" commented="no"><enum>(1)</enum><text>Artificial intelligence systems have rapidly advanced in capability and are increasingly being deployed across professional services, including healthcare, law, finance, and other sectors critical to the economy.</text></paragraph><paragraph id="id048622d1dd4742df9bef9cc69a3d1115" commented="no"><enum>(2)</enum><text>Industry leaders have publicly acknowledged the development of increasingly powerful artificial intelligence systems, with some discussing the potential for artificial general intelligence and superintelligence that could fundamentally reshape the society of the United States.</text></paragraph><paragraph id="id494064b1b157455c8064f866ed9c566a" commented="no"><enum>(3)</enum><text>The current lack of clarity regarding liability for artificial intelligence errors creates uncertainty that impedes the responsible integration of these beneficial technologies into professional services and economic activity.</text></paragraph><paragraph id="id2f699034a1b94649ac4e2a652ecec8ae" commented="no"><enum>(4)</enum><text>Many artificial intelligence systems operate with limited transparency regarding their capabilities, limitations, and default instructions, making it difficult for professional users to assess appropriate use cases and for legal systems to fairly allocate responsibility when errors occur.</text></paragraph><paragraph id="iddc790da612d14b99825064db65cb8c10" commented="no"><enum>(5)</enum><text>Learned professionals who utilize artificial intelligence tools in serving clients have professional obligations to understand the capabilities and limitations of the tools they employ, requiring access to clear information about system specifications and performance characteristics.</text></paragraph><paragraph id="id2f7f212fc85d4c2c80b6ca388a907568" commented="no"><enum>(6)</enum><text>Establishing clear standards for artificial intelligence transparency, coupled with appropriate liability frameworks, will promote responsible innovation while ensuring that the benefits and risks of artificial intelligence systems are properly understood and managed as these technologies continue to advance.</text></paragraph><paragraph id="idcbcceda971604deeb9696535f636705e" commented="no"><enum>(7)</enum><text>The development of artificial intelligence systems that may significantly impact the future of human civilization warrants a governance approach that balances innovation incentives with robust transparency requirements and appropriate allocation of responsibility among developers, professional users, and other stakeholders.</text></paragraph></section><section id="ideac456d65a774247b8f70cda2627fa6c"><enum>3.</enum><header>Definitions</header><text display-inline="no-display-inline">In this Act:</text><paragraph id="ida9b05be3996a43ab9fbafbc4ae444916"><enum>(1)</enum><header>Artificial intelligence</header><text>The term <term>artificial intelligence</term> has the meaning given the term in section 5002 of the National Artificial Intelligence Initiative Act of 2020 (<external-xref legal-doc="usc" parsable-cite="usc/15/9401">15 U.S.C. 9401</external-xref>).</text></paragraph><paragraph id="id861698e7460a4b9ca5b1264f14994781"><enum>(2)</enum><header>Client</header><text>The term <term>client</term> means a person that—</text><subparagraph commented="no" display-inline="no-display-inline" id="idd86a2387498d4149b86de228955bc99f"><enum>(A)</enum><text display-inline="yes-display-inline">engages the services of a learned professional;</text></subparagraph><subparagraph commented="no" display-inline="no-display-inline" id="ida3dcb66f9e4c4cd7ae580880dc0231c6"><enum>(B)</enum><text display-inline="yes-display-inline">relies upon the expertise, judgment, and advice of the learned professional; and</text></subparagraph><subparagraph commented="no" display-inline="no-display-inline" id="id55537db1835f402ba9b072ddb30e9fc3"><enum>(C)</enum><text display-inline="yes-display-inline">has a relationship with the learned professional that is governed by professional standards, codes of conduct, or regulations.</text></subparagraph></paragraph><paragraph id="id2fdb45892a524bb688a6c4e326f05fbb"><enum>(3)</enum><header>Developer</header><text>The term <term>developer</term> means a person that—</text><subparagraph id="id97ff5dc2081f48ffb751412b519485c9"><enum>(A)</enum><text>creates, designs, programs, trains, modifies, or substantially contributes to the creation or modification of an artificial intelligence product;</text></subparagraph><subparagraph id="id3e5715a424474a4fb4f301ca707c6c50"><enum>(B)</enum><text>exercises control over the design specifications, functionality, capabilities, limitations, or intended uses of an artificial intelligence product; or</text></subparagraph><subparagraph id="idb02211f08319431c99ccc89ed01eedb0"><enum>(C)</enum><text>markets, distributes, licenses, or makes available an artificial intelligence product under their own name, brand, or trademark, regardless of whether the person creates the original underlying technology of the artificial intelligence product.</text></subparagraph></paragraph><paragraph id="id4116105004e54ca09993133e76d67423"><enum>(4)</enum><header>Error</header><text>The term <term>error</term> means—</text><subparagraph id="idb860be1f70b8416c9bf5266bbe19c14d"><enum>(A)</enum><text>any output, action, recommendation, or material omission by an artificial intelligence product that is false, misleading, fabricated, deceptive, or incomplete in a manner that a reasonable developer could foresee would cause harm; or</text></subparagraph><subparagraph id="idb0a8723fb66a47c3a3b099fb23712aeb"><enum>(B)</enum><text>any failure of an artificial intelligence product to perform a function or task that the artificial intelligence product expressly or implicitly represents itself as capable of performing.</text></subparagraph></paragraph><paragraph id="id891fde2469bd45b5a92278f2033685f6"><enum>(5)</enum><header>Learned professional</header><text>The term <term>learned professional</term> means an individual who—</text><subparagraph id="ida30465f3c8aa41ab9e20923d8114692a"><enum>(A)</enum><text>possesses specialized education, training, knowledge, or skill in a profession;</text></subparagraph><subparagraph id="idf8767d683acb43609efb188b706e7d60"><enum>(B)</enum><text>is licensed, certified, or otherwise authorized by an appropriate Federal or State authority to practice in that profession;</text></subparagraph><subparagraph id="id438feb6514574d05a310a5d6f47b3218"><enum>(C)</enum><text>is bound by professional standards, ethical obligations, and a duty of care to clients; and</text></subparagraph><subparagraph id="id794072247f924487931a17d9e3d05b77"><enum>(D)</enum><text>exercises independent professional judgment when using tools, including artificial intelligence products, in the course of rendering professional services.</text></subparagraph></paragraph><paragraph id="id76216716e8c04b80bb378dfc78b5a99e" commented="no"><enum>(6)</enum><header>Model card</header><text>The term <term>model card</term> means a publicly available technical document in which a developer describes, consistent with industry standards and as rigorously as or more rigorously than industry peers, the training data sources, evaluation methodology, performance metrics, intended uses, limitations, and risk mitigations, including detection, evaluation, management, and safeguards against errors, of an artificial intelligence product.</text></paragraph><paragraph id="id6c063bf4d05d4860bb782f7a5d767bf5"><enum>(7)</enum><header>Model specification</header><text>The term <term>model specification</term>—</text><subparagraph commented="no" display-inline="no-display-inline" id="id30415f55fed4443f9fbe1ad5870e92e5"><enum>(A)</enum><text display-inline="yes-display-inline">means the text or other configuration instructions of an artificial intelligence product—</text><clause commented="no" display-inline="no-display-inline" id="id975f607513eb4426aeba97667c707014"><enum>(i)</enum><text display-inline="yes-display-inline">supplied by a developer;</text></clause><clause commented="no" display-inline="no-display-inline" id="idc7ea37424d5c4d8e880ccd9999ace2b7"><enum>(ii)</enum><text display-inline="yes-display-inline">that establish the intended base behavior, tone, constraints, or goals of the artificial intelligence product; and</text></clause><clause commented="no" display-inline="no-display-inline" id="idddd7b50e71f647a58dd3e702cf02beb5"><enum>(iii)</enum><text display-inline="yes-display-inline">that materially influence the outputs of the artificial intelligence product across users or sessions, including the system prompt provided to the model before engaging with user queries; and</text></clause></subparagraph><subparagraph commented="no" display-inline="no-display-inline" id="idfc8f801d5e514bdc8e18cafbf95842ad"><enum>(B)</enum><text>includes—</text><clause id="id34bdd25611e04ccab053b543710fb9d5"><enum>(i)</enum><text>the system prompt and any other text or images that the artificial intelligence product receives that are not visible to the end user;</text></clause><clause id="iddefa6eff56a44bdb8487c9dfba7fc0ce"><enum>(ii)</enum><text>any constitution or analogous guiding document used when training or fine‑tuning of an artificial intelligence product, including in automated schemes in which an artificial intelligence system trains another artificial intelligence system; and</text></clause><clause id="id9c9b570ad89d4621b2e3747adac44a31"><enum>(iii)</enum><text>the instructions, rubrics, or other guidance provided to human raters or evaluators of an artificial intelligence product the feedback of whom is used to train or fine-tune the artificial intelligence product.</text></clause></subparagraph></paragraph></section><section id="idec4b56cd3e444a5eb17fd6cc1c363ba3"><enum>4.</enum><header>Conditional immunity from civil liability for artificial intelligence developers</header><subsection id="id1b517463aa3f4d98a10c901f4cde458e"><enum>(a)</enum><header>Safe harbor eligibility</header><text>A developer shall be immune from civil liability for errors generated by an artificial intelligence product when used by a learned professional in the course of providing professional services to a client if the developer—</text><paragraph id="id2ae4d372653b4c8a90f7a07de096fc70"><enum>(1)</enum><text>prior to deployment of the artificial intelligence product, publicly releases and continuously maintains—</text><subparagraph id="idfea23a92ee3b4ab2aed8ef66e37398ac"><enum>(A)</enum><text>the model card for the artificial intelligence product; and</text></subparagraph><subparagraph id="id6ae7ec66a3974171aa1c939ebff1cc36"><enum>(B)</enum><text>the model specification for the artificial intelligence product, which may include redactions—</text><clause commented="no" display-inline="no-display-inline" id="id567a9411809142f29285f46dfa9f300b"><enum>(i)</enum><text display-inline="yes-display-inline">only relating to information that would reveal trade secrets unrelated to the safety of the artificial intelligence product; and</text></clause><clause commented="no" display-inline="no-display-inline" id="idd3c819044a104614ab72e78d75e5e62d"><enum>(ii)</enum><text display-inline="yes-display-inline">only if the developer furnishes contemporaneously with each redaction a written justification for the redaction identifying the basis for withholding the information as a trade secret; and</text></clause></subparagraph></paragraph><paragraph id="id8572c77b83b14524a00c7db059a9f6e9"><enum>(2)</enum><text>provides clear and conspicuous documentation to learned professionals describing the known limitations, failure modes, and appropriate domains of use for the artificial intelligence product.</text></paragraph></subsection><subsection id="id42a2c7098636497cb16db232cb0e1667"><enum>(b)</enum><header>Scope of immunity</header><text>The immunity provided under subsection (a) shall be conferred to a developer only for acts or omissions that do not constitute recklessness or willful misconduct by the developer.</text></subsection><subsection id="iddf9e507be4854be0a3cd40204ada4386"> <enum>(c)</enum> <header>Duty To update</header> <text>Immunity under subsection (a) relating to an artificial intelligence product shall not apply to a developer—</text>
        <paragraph commented="no" display-inline="no-display-inline"
          id="ide8c28c430c244c9885de7b3037f6a494">
          <enum>(1)</enum>
 <text display-inline="yes-display-inline">that does not update the model card, model specification, and documentation with respect to the artificial intelligence product as described in subsection (a)(1) by the date that is 30 days after the date on which the developer—</text>
          <subparagraph commented="no" display-inline="no-display-inline"
            id="idbe4e354e92324bf68e008f504998127e">
            <enum>(A)</enum>
 <text display-inline="yes-display-inline">deploys a new version of the artificial intelligence product; or</text>
          </subparagraph>
          <subparagraph commented="no" display-inline="no-display-inline"
            id="id6d532a4dc3874d2ea5fb9393fa547600">
            <enum>(B)</enum>
 <text>discovers a new and material failure mode affecting the artificial intelligence product; and</text>
          </subparagraph>
        </paragraph>
        <paragraph commented="no" display-inline="no-display-inline"
          id="id2e86f35a312d4e7790e0ef51bea64b92">
          <enum>(2)</enum>
 <text>of which the failure to make an update described in paragraph (1) by the applicable date described in that paragraph proximately causes a harm occurring after that date.</text>
        </paragraph>
 </subsection><subsection id="id37fdc17ff6ab45c4bc3ca6a691c981a0"><enum>(d)</enum><header>Preemption</header><paragraph commented="no" display-inline="no-display-inline" id="idcd418b4916ab4e6ab8a11e8ebbefe8b2"><enum>(1)</enum><header>Express preemption</header><text display-inline="yes-display-inline">This section shall apply to any claim arising under State law against a developer for an error arising from the use of an artificial intelligence product by a learned professional in providing professional services if the developer is immune from civil liability under subsection (a).</text></paragraph><paragraph commented="no" display-inline="no-display-inline" id="id97631d3644f14b008e2e1bd3ecd5bc1f"><enum>(2)</enum><header>Claims not preempted</header><text display-inline="yes-display-inline">Nothing in this section shall apply to a claim arising under State law against a developer based on fraud, knowing misrepresentation, or conduct outside the scope of professional use of an artificial intelligence product by a learned professional.</text></paragraph></subsection></section><section id="id6f957ab127294f19b0eb9575a352b7c3"><enum>5.</enum><header>Preservation of other immunities and privileges</header><text display-inline="no-display-inline">Nothing in this Act shall be construed to affect any immunity from civil liability established by Federal or State law or available at common law that is not related to the immunity established under section 4(a).</text></section><section id="id97b7d4d025c54882aa5da4f643738514"><enum>6.</enum><header>Effective date; applicability</header><text display-inline="no-display-inline">This Act—</text><paragraph commented="no" display-inline="no-display-inline" id="id3cddeac507ca456a90feaaf0ed8968cb"><enum>(1)</enum><text display-inline="yes-display-inline">shall take effect on December 1, 2025; and</text></paragraph><paragraph commented="no" display-inline="no-display-inline" id="id75d4f577695d4592a3b82b9e113a84a5"><enum>(2)</enum><text display-inline="yes-display-inline">shall apply to acts or omissions occurring on or after the date described in paragraph (1).</text></paragraph></section></legis-body></bill>

