Title: 
Official Title: To protect the safety of children on the internet.
Number of Sections: 17
Source: versions - Introduced in Senate
Media Type: text/xml

================================================================================

Section 1:
1.Short title; table of contents(a)Short titleThis Act may be cited as the Kids Online Safety Act.(b)Table of contentsThe table of contents for this Act is as follows:Sec. 1. Short title; table of contents.TITLE I—Kids Online SafetySec. 101. Definitions.Sec. 102. Duty of care.Sec. 103. Safeguards for minors.Sec. 104. Disclosure.Sec. 105. Transparency.Sec. 106. Market research.Sec. 107. Age verification study and report.Sec. 108. Guidance.Sec. 109. Enforcement.Sec. 110. Kids online safety council.Sec. 111. Effective date.Sec. 112. Rules of construction and other matters.TITLE II—Filter Bubble TransparencySec. 201. Definitions.Sec. 202. Requirement to allow users to see unmanipulated content on internet platforms.TITLE III—Relationship to State laws; severabilitySec. 301. Relationship to State laws.Sec. 302. Severability.

Section 2:
101.DefinitionsIn this title:(1)ChildThe term child means an individual who is under the age of 13.(2)Compulsive usageThe term compulsive usage means a persistent and repetitive use of a covered platform that significantly impacts one or more major life activities of an individual, including socializing, sleeping, eating, learning, reading, concentrating, communicating, or working.(3)Covered platform(A)In generalThe term covered platform means an online platform, online video game, messaging application, or video streaming service that connects to the internet and that is used, or is reasonably likely to be used, by a minor.(B)ExceptionsThe term covered platform does not include—(i)an entity acting in its capacity as a provider of—(I)a common carrier service subject to the Communications Act of 1934 (47 U.S.C. 151 et seq.) and all Acts amendatory thereof and supplementary thereto;(II)a broadband internet access service (as such term is defined for purposes of section 8.1(b) of title 47, Code of Federal Regulations, or any successor regulation);(III)an email service;(IV)a teleconferencing or video conferencing service that allows reception and transmission of audio or video signals for real-time communication, provided that—(aa)the service is not an online platform; and(bb)the real-time communication is initiated by using a unique link or identifier to facilitate access; or(V)a wireless messaging service, including such a service provided through short messaging service or multimedia messaging service protocols, that is not a component of, or linked to, an online platform and where the predominant or exclusive function is direct messaging consisting of the transmission of text, photos or videos that are sent by electronic means, where messages are transmitted from the sender to a recipient, and are not posted within an online platform or publicly;(ii)an organization not organized to carry on business for its own profit or that of its members;(iii)any public or private—(I)early childhood education program or preschool that provides for the care, development, and education of infants, toddlers, or young children who are not yet enrolled in kindergarten;(II)elementary school (as defined in section 8101 of the Elementary and Secondary Education Act of 1965 (20 U.S.C. 7801)) or secondary school (as so defined);(III)school providing career and technical education (as defined in section 3 of the Carl D. Perkins Career and Technical Education Act of 2006 (20 U.S.C. 2302));(IV)school providing adult education and literacy activities (as defined in section 203 of the Adult Education and Family Literacy Act (29 U.S.C. 3272)); or(V)institution of higher education (as defined in section 101, and subparagraphs (A) and (B) of section 102(a)(1), of the Higher Education Act of 1965 (20 U.S.C. 1001, 1002(a)(1)));(iv)a library (as defined in section 213 of the Library Services and Technology Act (20 U.S.C. 9122));(v)a news or sports coverage website or app where—(I)the inclusion of video content on the website or app is related to the website or app’s own gathering, reporting, or publishing of news content or sports coverage; and(II)the website or app is not otherwise an online platform;(vi)a product or service that primarily functions as business-to-business software, such as a cloud storage, file sharing, or file collaboration service;(vii)a virtual private network or similar service that exists predominantly to route internet traffic between locations; or(viii)a government entity with a .gov internet domain (as described in section 2215 of the Homeland Security Act of 2002 (6 U.S.C. 665)).(4)Design featureThe term design feature means any feature or component of a covered platform that will encourage or increase the frequency, time spent, or activity of minors on the covered platform. Design features include but are not limited to—(A)infinite scrolling or auto play;(B)rewards or incentives based on the frequency, time spent, or activity of minors on the covered platform;(C)notifications and push alerts;(D)badges or other visual award symbols based on the frequency, time spent, or activity of minors on the covered platform;(E)personalized design features;(F)in-game purchases; or(G)appearance altering filters.(5)GeolocationThe term geolocation has the meaning given the term geolocation information in section 1302 of the Children’s Online Privacy Protection Act of 1998 (15 U.S.C. 6501), as added by section 201(a).(6)Know or knowsThe term know or knows means to have actual knowledge or knowledge fairly implied on the basis of objective circumstances.(7)Microtransaction(A)In generalThe term microtransaction means a purchase made in an online video game (including a purchase made using a virtual currency that is purchasable or redeemable using cash or credit or that is included as part of a paid subscription service).(B)InclusionsSuch term includes a purchase involving surprise mechanics, new characters, or in-game items.(C)ExclusionsSuch term does not include—(i)a purchase made in an online video game using a virtual currency that is earned through gameplay and is not otherwise purchasable or redeemable using cash or credit or included as part of a paid subscription service; or(ii)a purchase of additional levels within the game or an overall expansion of the game.(8)MinorThe term minor means an individual who is under the age of 17.(9)Narcotic drugThe term narcotic drug has the meaning given such term in section 102 of the Controlled Substances Act (21 U.S.C. 802).(10)Online platform(A)In generalThe term online platform means any public-facing website, online service, online application, or mobile application that predominantly provides a community forum for user-generated content, such as sharing videos, images, games, audio files, or other content, including a social media service, social network, or virtual reality environment.(B)Incidental chat functionsA website, online service, online application, or mobile application is not an online platform solely on the basis that it includes a chat, comment, or other interactive function that is incidental to its predominant purpose.(11)Online video gameThe term online video game means a video game, including an educational video game, that connects to the internet and that allows a user to—(A)create and upload content other than content that is incidental to gameplay, such as character or level designs created by the user, preselected phrases, or short interactions with other users;(B)engage in microtransactions within the game; or(C)communicate with other users.(12)ParentThe term parent includes a legal guardian.(13)Personal dataThe term personal data has the same meaning as the term personal information as defined in section 1302 of the Children’s Online Privacy Protection Act (15 U.S.C. 6501).(14)Personalized design featureThe term personalized design feature means a fully or partially automated system, including a recommendation system, that is based on the collection of personal data of users and that encourages or increases the frequency, time spent, or activity of minors on the covered platform.(15)Personalized recommendation systemThe term personalized recommendation system means a fully or partially automated system used to suggest, promote, or rank content, including other users, hashtags, or posts, based on the personal data of users. A recommendation system that suggests, promotes, or ranks content based solely on the user’s language, city or town, or age shall not be considered a personalized recommendation system.(16)Sexual exploitation and abuseThe term sexual exploitation and abuse means any of the following:(A)Coercion and enticement, as described in section 2422 of title 18, United States Code.(B)Child sexual abuse material, as described in sections 2251, 2252, 2252A, and 2260 of title 18, United States Code.(C)Trafficking for the production of images, as described in section 2251A of title 18, United States Code.(D)Sex trafficking of children, as described in section 1591 of title 18, United States Code.(17)StateThe term State means each State of the United States, the District of Columbia, each commonwealth, territory, or possession of the United States, and each federally recognized Indian Tribe.(18)UserThe term user means, with respect to a covered platform, an individual who registers an account or creates a profile on the covered platform.

Section 3:
102.Duty of care(a)Prevention of harm to minorsA covered platform shall exercise reasonable care in the creation and implementation of any design feature to prevent and mitigate the following harms to minors where a reasonable and prudent person would agree that such harms were reasonably foreseeable by the covered platform and would agree that the design feature is a contributing factor to such harms:(1)Eating disorders, substance use disorders, and suicidal behaviors.(2)Depressive disorders and anxiety disorders when such conditions have objectively verifiable and clinically diagnosable symptoms and are related to compulsive usage.(3)Patterns of use that indicate compulsive usage.(4)Physical violence or online harassment activity that is so severe, pervasive, or objectively offensive that it impacts a major life activity of a minor.(5)Sexual exploitation and abuse of minors.(6)Distribution, sale, or use of narcotic drugs, tobacco products, cannabis products, gambling, or alcohol.(7)Financial harms caused by unfair or deceptive acts or practices (as defined in section 5(a)(4) of the Federal Trade Commission Act (15 U.S.C. 45(a)(4))).(b)Rules of construction(1)Nothing in subsection (a) shall be construed to require a covered platform to prevent or preclude any minor from—(A)deliberately and independently searching for, or specifically requesting, content; or(B)accessing resources and information regarding the prevention or mitigation of the harms described in subsection (a).(2)Nothing in this section shall be construed to allow a government entity to enforce subsection (a) based upon the viewpoint of users expressed by or through any speech, expression, or information protected by the First Amendment to the Constitution of the United States.

Section 4:
103.Safeguards for minors(a)Safeguards for minors(1)SafeguardsA covered platform shall provide a user or visitor that the covered platform knows is a minor with readily accessible and easy-to-use safeguards to, as applicable—(A)limit the ability of other users or visitors to communicate with the minor;(B)prevent other users or visitors, whether registered or not, from viewing the minor’s personal data collected by or shared on the covered platform, in particular restricting public access to personal data;(C)limit by default design features that encourage or increase the frequency, time spent, or activity of minors on the covered platform, such as infinite scrolling, auto playing, rewards for time spent on the platform, notifications, and other design features that result in compulsive usage of the covered platform by the minor;(D)control personalized recommendation systems, including the ability for a minor to have—(i)a prominently displayed option to opt out of such personalized recommendation systems, while still allowing the display of content based on a chronological format; and(ii)a prominently displayed option to limit types or categories of recommendations from such systems; and(E)restrict the sharing of the geolocation of the minor and provide notice regarding the tracking of the minor’s geolocation.(2)OptionA covered platform shall provide a user that the covered platform knows is a minor with a readily accessible and easy-to-use option to limit the amount of time spent by the minor on the covered platform.(3)Default safeguard settings for minorsA covered platform shall provide that, in the case of a user or visitor that the platform knows is a minor, the default setting for any safeguard described under paragraph (1) shall be the option available on the platform that provides the most protective level of control that is offered by the platform over privacy and safety for that user or visitor, unless otherwise enabled by the parent of the minor.(b)Parental tools(1)ToolsA covered platform shall provide readily accessible and easy-to-use parental tools for parents to support a user that the platform knows is a minor with respect to the use of the platform by that user.(2)RequirementsThe parental tools provided by a covered platform under paragraph (1) shall include—(A)the ability to manage a minor’s privacy and account settings, including the safeguards and options established under subsection (a), in a manner that allows parents to—(i)view the privacy and account settings; and(ii)in the case of a user that the platform knows is a child, change and control the privacy and account settings;(B)the ability to restrict purchases and financial transactions by the minor, where applicable; and(C)the ability to view metrics of total time spent on the covered platform and restrict time spent on the covered platform by the minor.(3)Notice to minorsA covered platform shall provide clear and conspicuous notice to a user when the tools described in this subsection are in effect and what settings or controls have been applied.(4)Default toolsA covered platform shall provide that, in the case of a user that the platform knows is a child, the tools required under paragraph (1) shall be enabled by default.(5)Application to existing accountsIf, prior to the effective date of this subsection, a covered platform provided a parent of a user that the platform knows is a child with notice and the ability to enable the parental tools described under this subsection in a manner that would otherwise comply with this subsection, and the parent opted out of enabling such tools, the covered platform is not required to enable such tools with respect to such user by default when this subsection takes effect.(c)Reporting mechanism(1)Reporting toolsA covered platform shall provide—(A)a readily accessible and easy-to-use means for users and visitors to submit reports to the covered platform of harms to a minor on the covered platform;(B)an electronic point of contact specific to matters involving harms to a minor; and(C)confirmation of the receipt of such a report and, within the applicable time period described in paragraph (2), a substantive response to the individual that submitted the report.(2)TimingA covered platform shall establish an internal process to receive and substantively respond to such reports in a reasonable and timely manner, but in no case later than—(A)10 days after the receipt of a report, if, for the most recent calendar year, the platform averaged more than 10,000,000 active users on a monthly basis in the United States;(B)21 days after the receipt of a report, if, for the most recent calendar year, the platform averaged less than 10,000,000 active users on a monthly basis in the United States; and(C)notwithstanding subparagraphs (A) and (B), if the report involves an imminent threat to the safety of a minor, as promptly as needed to address the reported threat to safety.(d)Advertising of illegal productsA covered platform shall not facilitate the advertising of narcotic drugs, cannabis products, tobacco products, gambling, or alcohol to an individual that the covered platform knows is a minor.(e)Rules of application(1)AccessibilityWith respect to safeguards and parental tools described under subsections (a) and (b), a covered platform shall provide—(A)information and control options in a clear and conspicuous manner that takes into consideration the differing ages, capacities, and developmental needs of the minors most likely to access the covered platform and does not encourage minors or parents to weaken or disable safeguards or parental tools;(B)readily accessible and easy-to-use controls to enable or disable safeguards or parental tools, as appropriate; and(C)information and control options in the same language, form, and manner as the covered platform provides the product or service used by minors and their parents.(2)Dark patterns prohibitionIt shall be unlawful for any covered platform to design, embed, modify, or manipulate a user interface of a covered platform with the purpose or substantial effect of obscuring, subverting or impairing user autonomy, decision-making, or choice with respect to safeguards or parental tools required under this section.(3)Timing considerations(A)No interruption to gameplaySubsections (a)(1)(C) and (b)(3) shall not require an online video game to interrupt the natural sequence of gameplay, such as progressing through game levels or finishing a competition.(B)Application of changes to offline devices or accountsIf a user’s device or user account does not have access to the internet at the time of a change to parental tools, a covered platform shall apply changes the next time the device or user is connected to the internet.(f)Device or console controls(1)In generalNothing in this section shall be construed to prohibit a covered platform from integrating its products or service with, or duplicate controls or tools provided by, third-party systems, including operating systems or gaming consoles, to meet the requirements imposed under subsections (a) and (b) relating to safeguards for minors and parental tools, provided that—(A)the controls or tools meet such requirements; and(B)the minor or parent is provided sufficient notice of the integration and use of the parental tools.(2)Preservation of protectionsIn the event of a conflict between the controls or tools of a third-party system, including operating systems or gaming consoles, and a covered platform, the covered platform is not required to override the controls or tools of a third-party system if it would undermine the protections for minors from the safeguards or parental tools imposed under subsections (a) and (b).(g)ExceptionA covered platform shall provide the safeguards and parental tools described in subsections (a) and (b) to an educational agency or institution (as defined in section 444 of the General Education Provisions Act (20 U.S.C. 1232g(a)(3))), rather than to the user or visitor, when the covered platform is acting on behalf of the educational agency or institution subject to a written contract that complies with the requirements of the Children’s Online Privacy Protection Act (15 U.S.C. 6501 et seq.) and the Family Educational Rights and Privacy Act of 1974 (20 U.S.C. 1232g).(h)Rules of constructionNothing in this section shall be construed to—(1)prevent a covered platform from taking reasonable measures to—(A)block, detect, or prevent the distribution of unlawful, obscene, or other harmful material to minors as described in section 102(a); or(B)block or filter spam, prevent criminal activity, or protect the security of a platform or service;(2)require the disclosure of the browsing behavior, search history, messages, contact list, or other content or metadata of the communications of a minor;(3)prevent a covered platform from using a personalized recommendation system to display content to a minor if the system only uses information on—(A)the language spoken by the minor;(B)the city the minor is located in; or(C)the minor’s age;(4)prevent an online video game from disclosing a username or other user identification for the purpose of competitive gameplay or to allow for the reporting of users;(5)prevent a covered platform from contracting or entering into an agreement with a third-party entity, whose primary or exclusive function is to provide the safeguards or parental tools required under subsections (a) and (b) or to offer similar or stronger protective capabilities for minors, to assist with meeting the requirements imposed under subsections (a) and (b); or(6)prevent a parent or user from authorizing a third-party entity described in subparagraph (5) to implement such safeguards or parental tools or provide similar or stronger protective capabilities for minors, at the choice of the parent or user.

Section 5:
104.Disclosure(a)Notice(1)Registration or purchasePrior to registration or purchase of a covered platform by an individual that the platform knows is a minor, the platform shall provide clear, conspicuous, and easy-to-understand—(A)notice of the policies and practices of the covered platform with respect to safeguards for minors;(B)information about how to access the safeguards and parental tools required under section 103; and(C)notice about how to access the information on personalized recommendation systems required under subsection (b).(2)Notification(A)Notice and acknowledgmentIn the case of an individual that a covered platform knows is a child, the platform shall provide information about the parental tools and safeguards required under section 103 to a parent of the child and obtain verifiable consent (as defined in section 1302 of the Children’s Online Privacy Protection Act of 1998 (15 U.S.C. 6501)).(B)Reasonable effortA covered platform shall be deemed to have satisfied the requirement described in subparagraph (A) if the covered platform is in compliance with the requirements of the Children’s Online Privacy Protection Act of 1998 (15 U.S.C. 6501 et seq.) to use reasonable efforts (taking into consideration available technology) to provide a parent with the information described in subparagraph (A) and to obtain verifiable consent as required.(3)Consolidated noticesFor purposes of this title, a covered platform may consolidate the process for providing information under this subsection and obtaining verifiable consent or the consent of the minor involved (as applicable) as required under this subsection with the obligations of the covered platform to provide relevant notice and obtain verifiable consent under the Children’s Online Privacy Protection Act of 1998 (15 U.S.C. 6501 et seq.).(4)GuidanceThe Federal Trade Commission may issue guidance to assist covered platforms in complying with the specific notice requirements of this subsection.(b)Personalized recommendation systemA covered platform that operates a personalized recommendation system shall set out in its terms and conditions, in a clear, conspicuous, and easy-to-understand manner—(1)an overview of how each personalized recommendation system is used by the covered platform to provide information to minors, including how such systems use the personal data of minors; and(2)information about options for minors or their parents to opt out of or control the personalized recommendation system (as applicable).(c)Advertising and marketing information and labels(1)Information and labelsA covered platform shall provide clear, conspicuous, and easy-to-understand labels and information, which can be provided through a link to another web page or disclosure, to minors on advertisements regarding—(A)the name of the product, service, or brand and the subject matter of an advertisement; and(B)whether particular media displayed to the minor is an advertisement or marketing material, including disclosure of endorsements of products, services, or brands made for commercial consideration by other users of the platform.(2)GuidanceThe Federal Trade Commission may issue guidance to assist covered platforms in complying with the requirements of this subsection, including guidance about the minimum level of information and labels for the disclosures required under paragraph (1).(d)Resources for parents and minorsA covered platform shall provide to minors and parents clear, conspicuous, easy-to-understand, and comprehensive information in a prominent location, which may include a link to a web page, regarding—(1)the policies and practices of the covered platform with respect to safeguards for minors; and(2)how to access the safeguards and parental tools required under section 103.(e)Resources in additional languagesA covered platform shall ensure, to the extent practicable, that the disclosures required by this section are made available in the same language, form, and manner as the covered platform provides any product or service used by minors and their parents.

Section 6:
105.Transparency(a)In generalSubject to subsection (b), not less frequently than once a year, a covered platform shall issue a public report that addresses the matters in subsection (c) based on an independent, third-party audit of the covered platform with a reasonable level of assurance.(b)Scope of applicationThe requirements of this section shall apply to a covered platform if—(1)for the most recent calendar year, the platform averaged more than 10,000,000 active users on a monthly basis in the United States; and(2)the platform predominantly provides a community forum for user-generated content and discussion, including sharing videos, images, games, audio files, discussion in a virtual setting, or other content, such as acting as a social media platform, virtual reality environment, or a social network service.(c)Content(1)TransparencyThe public reports required of a covered platform under this section shall include—(A)an assessment of the extent to which the platform is likely to be accessed by minors;(B)a description of the commercial interests of the covered platform being used by minors;(C)an accounting, based on the data held by the covered platform, of—(i)the number of users using the covered platform that the platform knows to be minors in the United States;(ii)the median and mean amounts of time spent on the platform by users known to be minors in the United States who have accessed the platform during the reporting year on a daily, weekly, and monthly basis; and(iii)the amount of content being accessed by users that the platform knows to be minors in the United States that is in English, and the top 5 non-English languages used by users accessing the platform in the United States;(D)an accounting of total reports received through the reporting mechanism described in section 103, disaggregated by language, including English and the top 5 non-English languages used by users accessing the platform from the United States (as identified under subparagraph (C)(iii)); and(E)an assessment of the safeguards and parental tools under section 103, representations regarding the use of the personal data of minors, and other matters regarding compliance with this title.(2)EvaluationThe public reports required under this section shall include—(A)an assessment based on aggregate data on the exercise of safeguards and parental tools described in section 103, and other competent and reliable empirical evidence;(B)a description of whether and how the covered platform uses design features that increase, sustain, or extend the use of a product or service by a minor;(C)a description of whether, how, and for what purpose the platform collects or processes categories of personal data, including how personal data is used to operate personalized recommendation systems related to minors;(D)an evaluation of the efficacy of safeguards for minors and parental tools under section 103, and any issues in delivering such safeguards and parental tools; and(E)an assessment of differences, with respect to the matters described in subparagraphs (A) through (D), across different English and non-English languages and efficacy of safeguards in those languages.(3)MitigationThe public reports required of a covered platform under this section shall include, for English and the top 5 non-English languages used by users accessing the platform from the United States (as identified under paragraph (2)(C)(iii))—(A)a description of the safeguards and parental tools available to minors and parents on the covered platform;(B)a description of the prevention and mitigation measures a covered platform may take, if any, in response to the assessments conducted under paragraph (2), including steps take to provide the most protective level of control over safety by default;(C)a description of the processes used for the creation and implementation of any design feature that will be used by minors;(D)a description and assessment of handling reports under the requirement of section 103(c), including the rate of response, timeliness, and substantiveness of responses; and(E)the status of implementing prevention and mitigation measures identified in prior assessments.(d)Reasonable inspectionIn conducting an inspection of the reasonably foreseeable risk of harm to minors under this section, an independent, third-party auditor shall—(1)take into consideration the function of personalized recommendation systems;(2)consult parents and youth experts, including youth and families with relevant past or current experience, public health and mental health nonprofit organizations, health and development organizations, and civil society with respect to the prevention of harms to minors;(3)conduct research based on experiences of minors that use the covered platform, including reports under section 103(c) and information provided by law enforcement;(4)take account of research, including research regarding design features, marketing, or product integrity, industry best practices, or outside research;(5)take into consideration indicia or inferences of age of users, in addition to any self-declared information about the age of users; and(6)take into consideration differences in risk of reasonably foreseeable harms and effectiveness of safeguards across English and non-English languages.(e)Cooperation with independent, third-Party auditTo facilitate the report required by subsection (c), a covered platform shall—(1)provide or otherwise make available to the independent third-party conducting the audit all information and material in its possession, custody, or control that is relevant to the audit;(2)provide or otherwise make available to the independent third-party conducting the audit access to all network, systems, and assets relevant to the audit; and(3)disclose all relevant facts to the independent third-party conducting the audit, and not misrepresent in any manner, expressly or by implication, any relevant fact.(f)Privacy safeguards(1)In generalIn issuing the public reports required under this section, a covered platform shall take steps to safeguard the privacy of its users, including ensuring that data is presented in a de-identified, aggregated format such that it is not reasonably linkable to any user.(2)Rule of constructionThis section shall not be construed to require the disclosure of information that will lead to material vulnerabilities for the privacy of users or the security of a covered platform’s service or create a significant risk of the violation of Federal or State law.(3)Definition of de-identifiedAs used in this subsection, the term de-identified means data that does not identify and is not linked or reasonably linkable to a device that is linked or reasonably linkable to an individual, regardless of whether the information is aggregated.(g)LocationThe public reports required under this section should be posted by a covered platform on an easy to find location on a publicly available website.

Section 7:
106.Market research(a)Prohibition of research on
 childrenA covered platform shall not, in the case of a user or visitor that the covered platform knows is a child, conduct market or product-focused research on such child.(b)Market research on minorsA covered platform may not, in the case of a user or visitor that the online platform knows is a minor, conduct market or product-focused research on such minor, unless the covered platform obtains verifiable parental consent (as defined in section 1302 of the Children’s Online Privacy Protection Act of 1998 (15 U.S.C. 6501)) prior to conducting such research on such minor.

Section 8:
107.Age verification study and report(a)StudyThe Secretary of Commerce, in coordination with the Federal Communications Commission and the Federal Trade Commission, shall conduct a study evaluating the most technologically feasible methods and options for developing systems to verify age at the device or operating system level.(b)ContentsSuch study shall consider—(1)the benefits of creating a device or operating system level age verification system;(2)what information may need to be collected to create this type of age verification system;(3)the accuracy of such systems and their impact or steps to improve accessibility, including for individuals with disabilities;(4)how such a system or systems could verify age while mitigating risks to user privacy and data security and safeguarding minors’ personal data, emphasizing minimizing the amount of data collected and processed by covered platforms and age verification providers for such a system;(5)the technical feasibility, including the need for potential hardware and software changes, including for devices currently in commerce and owned by consumers; and(6)the impact of different age verification systems on competition, particularly the risk of different age verification systems creating barriers to entry for small companies.(c)ReportNot later than 1 year after the date of enactment of this Act, the agencies described in subsection (a) shall submit a report containing the results of the study conducted under such subsection to the Committee on Commerce, Science, and Transportation of the Senate and the Committee on Energy and Commerce of the House of Representatives.

Section 9:
108.Guidance(a)In generalNot later than 18 months after the date of enactment of this Act, the Federal Trade Commission shall issue guidance to—(1)provide information and examples for covered platforms and auditors regarding the following, with consideration given to differences across English and non-English languages—(A)identifying design features that encourage or increase the frequency, time spent, or activity of minors on the covered platform;(B)safeguarding minors against the possible misuse of parental tools;(C)best practices in providing minors and parents the most protective level of control over privacy and safety;(D)using indicia or inferences of age of users for assessing use of the covered platform by minors;(E)methods for evaluating the efficacy of safeguards set forth in this title; and(F)providing additional parental tool options that allow parents to address the harms described in section 102(a); and(2)outline conduct that does not have the purpose or substantial effect of subverting or impairing user autonomy, decision-making, or choice, or of causing, increasing, or encouraging compulsive usage for a minor, such as—(A)de minimis user interface changes derived from testing consumer preferences, including different styles, layouts, or text, where such changes are not done with the purpose of weakening or disabling safeguards or parental tools;(B)algorithms or data outputs outside the control of a covered platform; and(C)establishing default settings that provide enhanced privacy protection to users or otherwise enhance their autonomy and decision-making ability.(b)Guidance on knowledge standardNot later than 18 months after the date of enactment of this Act, the Federal Trade Commission shall issue guidance to provide information, including best practices and examples, for covered platforms to understand how the Commission would determine whether a covered platform had knowledge fairly implied on the basis of objective circumstances for purposes of this title.(c)Limitation on Federal Trade
 Commission guidance(1)Effect of guidanceNo guidance issued by the Federal Trade Commission with respect to this title shall—(A)confer any rights on any person, State, or locality; or(B)operate to bind the Federal Trade Commission or any court, person, State, or locality to the approach recommended in such guidance.(2)Use in enforcement actionsIn any enforcement action brought pursuant to this title, the Federal Trade Commission or a State attorney general, as applicable—(A)shall allege a violation of a provision of this title; and(B)may not base such enforcement action on, or execute a consent order based on, practices that are alleged to be inconsistent with guidance issued by the Federal Trade Commission with respect to this title, unless the practices are alleged to violate a provision of this title.For purposes of
                            enforcing this title, State attorneys general shall take into account
                            any guidance issued by the Commission under subsection
 (b).

Section 10:
109.Enforcement(a)Enforcement by Federal Trade Commission(1)Unfair and deceptive acts or practicesA violation of this title shall be treated as a violation of a rule defining an unfair or deceptive act or practice prescribed under section 18(a)(1)(B) of the Federal Trade Commission Act (15 U.S.C. 57a(a)(1)(B)).(2)Powers of the Commission(A)In generalThe Federal Trade Commission (referred to in this section as the Commission) shall enforce this title in the same manner, by the same means, and with the same jurisdiction, powers, and duties as though all applicable terms and provisions of the Federal Trade Commission Act (15 U.S.C. 41 et seq.) were incorporated into and made a part of this title.(B)Privileges and immunitiesAny person that violates this title shall be subject to the penalties, and entitled to the privileges and immunities, provided in the Federal Trade Commission Act (15 U.S.C. 41 et seq.).(3)Authority preservedNothing in this title shall be construed to limit the authority of the Commission under any other provision of law.(b)Enforcement by State attorneys general(1)In general(A)Civil actionsIn any case in which the attorney general of a State has reason to believe that a covered platform has violated or is violating section 103, 104, or 105, the State, as parens patriae, may bring a civil action on behalf of the residents of the State in a district court of the United States or a State court of appropriate jurisdiction to—(i)enjoin any practice that violates section 103, 104, or 105;(ii)enforce compliance with section 103, 104, or 105;(iii)on behalf of residents of the State, obtain damages, restitution, or other compensation, each of which shall be distributed in accordance with State law; or(iv)obtain such other relief as the court may consider to be appropriate.(B)Notice(i)In generalBefore filing an action under subparagraph (A), the attorney general of the State involved shall provide to the Commission—(I)written notice of that action; and(II)a copy of the complaint for that action.(ii)Exemption(I)In generalClause (i) shall not apply with respect to the filing of an action by an attorney general of a State under this paragraph if the attorney general of the State determines that it is not feasible to provide the notice described in that clause before the filing of the action.(II)NotificationIn an action described in subclause (I), the attorney general of a State shall provide notice and a copy of the complaint to the Commission at the same time as the attorney general files the action.(2)Intervention(A)In generalOn receiving notice under paragraph (1)(B), the Commission shall have the right to intervene in the action that is the subject of the notice.(B)Effect of interventionIf the Commission intervenes in an action under paragraph (1), it shall have the right—(i)to remove the action to the appropriate United States district court;(ii)to be heard with respect to any matter that arises in that action; and(iii)to file a petition for appeal.(3)ConstructionFor purposes of bringing any civil action under paragraph (1), nothing in this title shall be construed to prevent an attorney general of a State from exercising the powers conferred on the attorney general by the laws of that State to—(A)conduct investigations;(B)administer oaths or affirmations; or(C)compel the attendance of witnesses or the production of documentary and other evidence.(4)Actions by the commissionIn any case in which an action is instituted by or on behalf of the Commission for violation of this title, no State may, during the pendency of that action, institute a separate action under paragraph (1) against any defendant named in the complaint in the action instituted by or on behalf of the Commission for that violation.(5)Venue; service of process(A)VenueAny action brought under paragraph (1) may be brought in—(i)the district court of the United States that meets applicable requirements relating to venue under section 1391 of title 28, United States Code; or(ii)a State court of competent jurisdiction.(B)Service of processIn an action brought under paragraph (1) in a district court of the United States, process may be served wherever defendant—(i)is an inhabitant; or(ii)may be found.(6)LimitationA violation of section 102 shall not form the basis of liability in any action brought by the attorney general of a State under a State law.

Section 11:
110.Kids online safety council(a)EstablishmentThere is established a Kids Online Safety Council (in this section referred to as the Council).(b)DutiesThe duties of the Council shall be to provide reports to Congress with recommendations and advice on matters related to the safety of minors online. The matters to be addressed by the Council shall include—(1)identifying emerging or current risks of harms to minors associated with online platforms;(2)recommending measures and methods for assessing, preventing, and mitigating harms to minors online;(3)recommending methods and themes for conducting research regarding online harms to minors, including in English and non-English languages; and(4)recommending best practices and clear, consensus-based technical standards for transparency reports and audits, as required under this title, including methods, criteria, and scope to promote overall accountability.(c)Number and appointment of membersThe Council shall be comprised of 11 members, of whom—(1)3 members shall be appointed by the President, including—(A)the Secretary of Commerce or a designee of the Secretary; and(B)the Secretary of Health and Human Services or a designee of the Secretary;(2)2 members shall be appointed by the Speaker of the House of Representatives;(3)2 members shall be appointed by the Minority Leader of the House of Representatives;(4)2 members shall be appointed by the Majority Leader of the Senate; and(5)2 members shall be appointed by the Minority Leader of the Senate.(d)Timing of appointmentsEach of the appointments under subsection (c) shall be made not later than 180 days after the date of the enactment of this Act.(e)Terms; vacanciesEach member of the Council shall be appointed for the life of the Council, and a vacancy in the Council shall be filled in the manner in which the original appointment was made.(f)Chairperson; vice chairpersonThe Council, once it has been fully appointed, shall select its own Chair and Vice Chair.(g)ParticipationThe Council shall consist of 1 member from each of the following:(1)academic experts with specific expertise in the prevention of online harms to minors;(2)researchers with specific expertise in social media studies;(3)parents with demonstrated experience in child online safety;(4)youth representatives with demonstrated experience in child online safety;(5)educators with demonstrated experience in child online safety;(6)representatives of online platforms;(7)representatives of online video games;(8)State attorneys general or their designees acting in State or local government; and(9)representatives of communities of socially disadvantaged individuals (as defined in section 8 of the Small Business Act (15 U.S.C. 637)).(h)Reports(1)Interim reportNot later than 1 year after the date of the initial meeting of the Council, the Council shall submit to Congress an interim report that includes a detailed summary of the work of the Council and any preliminary findings of the Council.(2)Final reportNot later than 3 years after the date of the initial meeting of the Council, the Council shall submit to Congress a final report that includes—(A)a detailed statement of the findings and conclusions of the Council;(B)dissenting opinions of any member of the Council who does not support the findings and conclusions referred to in subparagraph (A); and(C)any recommendations for legislative and administrative actions to address online safety for children and prevent harms to minors.(i)TerminationThe Council shall terminate not later than 30 days after the submission of the final report required under subsection (h)(2).(j)Non-Applicability of FACAThe Kids Online Safety Council shall not be subject to chapter 10 of title 5, United States Code (commonly referred to as the Federal Advisory Committee Act).

Section 12:
111.Effective dateExcept as otherwise provided in this title, this title shall take effect on the date that is 18 months after the date of enactment of this Act.

Section 13:
112.Rules of construction and other matters(a)Relationship to other lawsNothing in this title shall be construed to—(1)preempt section 444 of the General Education Provisions Act (20 U.S.C. 1232g, commonly known as the Family Educational Rights and Privacy Act of 1974) or other Federal or State laws governing student privacy;(2)preempt the Children’s Online Privacy Protection Act of 1998 (15 U.S.C. 6501 et seq.) or any rule or regulation promulgated under such Act;(3)authorize any action that would conflict with section 18(h) of the Federal Trade Commission Act (15 U.S.C. 57a(h)); or(4)expand, limit the scope, or alter the meaning of section 230 of the Communications Act of 1934 (commonly known as section 230 of the Communications Decency Act of 1996) (47 U.S.C. 230).(b)Determination of fairly implied on the basis of objective
 circumstancesFor purposes of enforcing this title, in making a determination as to whether covered platform has knowledge fairly implied on the basis of objective circumstances that a specific user is a minor, the Federal Trade Commission or a State attorney general shall rely on competent and reliable evidence, taking into account the totality of the circumstances, including whether a reasonable and prudent person under the circumstances would have known that the user is a minor.(c)Protections for privacyNothing in this title, including a determination described in subsection (b), shall be construed to require—(1)the affirmative collection of any personal data with respect to the age of users that a covered platform is not already collecting in the normal course of business; or(2)a covered platform to implement an age gating or age verification functionality.(d)ComplianceNothing in this title shall be construed to restrict a covered platform’s ability to—(1)cooperate with law enforcement agencies regarding activity that the covered platform reasonably and in good faith believes may violate Federal, State, or local laws, rules, or regulations;(2)comply with a lawful civil, criminal, or regulatory inquiry, subpoena, or summons by Federal, State, local, or other government authorities;(3)investigate, establish, exercise, respond to, or defend against legal claims;(4)prevent, detect, protect against, or respond to any security incident, identity theft, fraud, harassment, malicious or deceptive activity, or any illegal activities; or(5)investigate or report those responsible for any action described in paragraph (4).(e)Application to video streaming servicesA video streaming service shall be deemed to be in compliance with this title if it predominantly consists of news, sports, entertainment, or other video programming content that is preselected by the provider and not user-generated, and—(1)any chat, comment, or interactive functionality is provided incidental to, directly related to, or dependent on provision of such content; and(2)if such video streaming service requires account owner registration and is not predominantly news or sports, the service includes the capability—(A)to limit a minor’s access to the service, which may utilize a system of age-rating;(B)to limit the automatic playing of on-demand content selected by a personalized recommendation system for an individual that the service knows is a minor;(C)for a parent to manage a minor’s privacy and account settings, and restrict purchases and financial transactions by a minor, where applicable;(D)to provide an electronic point of contact specific to matters described in this paragraph;(E)to offer a clear, conspicuous, and easy-to-understand notice of its policies and practices with respect to the capabilities described in this paragraph; and(F)when providing on-demand content, to employ measures that safeguard against serving advertising for narcotic drugs, cannabis products, tobacco products, gambling, or alcohol directly to the account or profile of an individual that the service knows is a minor.

Section 14:
201.DefinitionsIn this title:(1)Algorithmic ranking systemThe term algorithmic ranking system means a computational process, including one derived from algorithmic decision-making, machine learning, statistical analysis, or other data processing or artificial intelligence techniques, used to determine the selection, order, relative prioritization, or relative prominence of content from a set of information that is provided to a user on an online platform, including the ranking of search results, the provision of content recommendations, the display of social media posts, or any other method of automated content selection.(2)Approximate geolocation informationThe term approximate geolocation information means information that identifies the location of an individual, but with a precision of less than 5 miles.(3)CommissionThe term Commission means the Federal Trade Commission.(4)Connected deviceThe term connected device means an electronic device that—(A)is capable of connecting to the internet, either directly or indirectly through a network, to communicate information at the direction of an individual;(B)has computer processing capabilities for collecting, sending, receiving, or analyzing data; and(C)is primarily designed for or marketed to consumers.(5)Input-transparent algorithm(A)In generalThe term input-transparent algorithm means an algorithmic ranking system that does not use the user-specific data of a user to determine the selection, order, relative prioritization, or relative prominence of information that is furnished to such user on an online platform, unless the user-specific data is expressly provided to the platform by the user for such purpose.(B)Data expressly provided to the platformFor purposes of subparagraph (A), user-specific data that is provided by a user for the express purpose of determining the selection, order, relative prioritization, or relative prominence of information that is furnished to such user on an online platform—(i)includes user-supplied search terms, filters, speech patterns (if provided for the purpose of enabling the platform to accept spoken input or selecting the language in which the user interacts with the platform), saved preferences, the resumption of a previous search, and the current precise geolocation information that is supplied by the user;(ii)includes the user’s current approximate geolocation information;(iii)includes data submitted to the platform by the user that expresses the user’s desire to receive particular information, such as the social media profiles the user follows, the video channels the user subscribes to, or other content or sources of content on the platform the user has selected;(iv)does not include the history of the connected device of the user, including the history of web searches and browsing, previous geographical locations, physical activity, device interaction, and financial transactions of the user; and(v)does not include inferences about the user or the connected device of the user, without regard to whether such inferences are based on data described in clause (i) or (iii).(6)Online platform(A)In generalSubject to subparagraph (B), the term online platform means any public-facing website, online service, online application, or mobile application that predominantly provides a community forum for user-generated content, such as sharing videos, images, games, audio files, or other content, including a social media service, social network, or virtual reality environment.(B)Scope(i)Incidental chat functionsA website, online service, online application, or mobile application is not an online platform solely on the basis that it includes a chat, comment, or other interactive function that is incidental to its predominant purpose.(ii)Review sitesA website, online service, online application, or mobile application that has the predominant purpose of providing travel reviews is not an online platform.(7)Opaque algorithmThe term opaque algorithm—(A)means an algorithmic ranking system that determines the selection, order, relative prioritization, or relative prominence of information that is furnished to such user on an online platform based, in whole or part, on user-specific data that was not expressly provided by the user to the platform for such purpose; and(B)does not include an algorithmic ranking system used by an online platform if—(i)the only user-specific data (including inferences about the user) that the system uses is information relating to the age of the user; and(ii)such information is only used to restrict the access of a user to content on the basis that the individual is not old enough to access such content.(8)Precise geolocation informationThe term precise geolocation information means geolocation information that identifies the location of an individual to within a range of 5 miles or less.(9)User-specific dataThe term user-specific data means information relating to an individual or a specific connected device that would not necessarily be true of every individual or device.

Section 15:
202.Requirement to allow users to see unmanipulated content on internet
 platforms(a)In generalBeginning on the date that is 1 year after the date of enactment of this Act, it shall be unlawful for any person to operate an online platform that uses an opaque algorithm unless the person complies with the requirements of subsection (b).(b)Opaque algorithm requirements(1)In generalThe requirements of this subsection with respect to a person that operates an online platform that uses an opaque algorithm are the following:(A)The person provides users of the platform with the following notices:(i)Notice that the platform uses an opaque algorithm that uses user-specific data to select the content the user sees. Such notice shall be presented in a clear and conspicuous manner on the platform whenever the user interacts with an opaque algorithm for the first time, and may be a one-time notice that can be dismissed by the user.(ii)Notice, to be included in the terms and conditions of the online platform, in a clear, accessible, and easily comprehensible manner that is to be updated whenever the online platform makes a material change, of—(I)the most salient features, inputs, and parameters used by the algorithm;(II)how any user-specific data used by the algorithm is collected or inferred about a user of the platform, and the categories of such data;(III)any options that the online platform makes available for a user of the platform to opt out or exercise options under subparagraph (B), modify the profile of the user or to influence the features, inputs, or parameters used by the algorithm; and(IV)any quantities, such as time spent using a product or specific measures of engagement or social interaction, that the algorithm is designed to optimize, as well as a general description of the relative importance of each quantity for such ranking.(B)The online platform enables users to easily switch between the opaque algorithm and an input-transparent algorithm in their use of the platform.(2)Rule of constructionNothing in this subsection shall be construed to require an online platform to disclose any information, including data or algorithms—(A)relating to a trade secret or other protected intellectual property;(B)that is confidential business information; or(C)that is privileged.(3)Prohibition on differential pricingAn online platform shall not deny, charge different prices or rates for, or condition the provision of a service or product to a user based on the user’s election to use an input-transparent algorithm in their use of the platform, as provided under paragraph (1)(B).(4)Special ruleNotwithstanding paragraphs (1) and (2), an online platform shall provide the notice and opt-out described in paragraphs (1) and (2) to the educational agency or institution (as defined in section 444(a)(3) of the General Education Provisions Act (20 U.S.C. 1232g(a)(3)), rather than to the user, when the online platform is acting on behalf of an educational agency or institution (as so defined), subject to a written contract that complies with the requirements of the Children’s Online Privacy Protection Act of 1998 (15 U.S.C. 1232g(a)(3)) and section 444 of the General Education Provisions Act (20 U.S.C. 1232g) (commonly known as the Family Educational Rights and Privacy Act of 1974).(c)Enforcement by Federal Trade Commission(1)Unfair or deceptive acts or practicesA violation of this section by an operator of an online platform shall be treated as a violation of a rule defining an unfair or deceptive act or practice prescribed under section 18(a)(1)(B) of the Federal Trade Commission Act (15 U.S.C. 57a(a)(1)(B)).(2)Powers of commission(A)In generalThe Federal Trade Commission shall enforce this section in the same manner, by the same means, and with the same jurisdiction, powers, and duties as though all applicable terms and provisions of the Federal Trade Commission Act (15 U.S.C. 41 et seq.) were incorporated into and made a part of this section.(B)Privileges and immunitiesAny person who violates this section shall be subject to the penalties and entitled to the privileges and immunities provided in the Federal Trade Commission Act (15 U.S.C. 41 et seq.).(C)Authority preservedNothing in this section shall be construed to limit the authority of the Commission under any other provision of law.(d)Rule of construction To preserve personalized blocksNothing in this section shall be construed to limit or prohibit an online platform’s ability to, at the direction of an individual user or group of users, restrict another user from searching for, finding, accessing, or interacting with such user’s or group’s account, content, data, or online community.

Section 16:
301.Relationship to State lawsThe provisions of this Act shall preempt any State law, rule, or regulation only to the extent that such State law, rule, or regulation conflicts with a provision of this Act. Nothing in this Act shall be construed to prohibit a State from enacting a law, rule, or regulation that provides greater protection to minors than the protection provided by the provisions of this Act.

Section 17:
302.SeverabilityIf any provision of this Act, or an amendment made by this Act, is determined to be unenforceable or invalid, the remaining provisions of this Act and the amendments made by this Act shall not be affected.


================================================================================

Raw Text:
119 S1748 IS: Kids Online Safety Act
U.S. Senate
2025-05-14
text/xml
EN
Pursuant to Title 17 Section 105 of the United States Code, this file is not subject to copyright protection and is in the public domain.



II119th CONGRESS1st SessionS. 1748IN THE SENATE OF THE UNITED STATESMay 14, 2025Mrs. Blackburn (for herself, Mr. Blumenthal, Mr.
                    Thune, and Mr. Schumer)
                introduced the following bill; which was read twice and referred to the
                    Committee on Commerce, Science, and
 TransportationA BILLTo protect the safety of children on the internet.1.Short title; table of contents(a)Short titleThis Act may be cited as the Kids Online Safety Act.(b)Table of contentsThe table of contents for this Act is as follows:Sec. 1. Short title; table of contents.TITLE I—Kids Online SafetySec. 101. Definitions.Sec. 102. Duty of care.Sec. 103. Safeguards for minors.Sec. 104. Disclosure.Sec. 105. Transparency.Sec. 106. Market research.Sec. 107. Age verification study and report.Sec. 108. Guidance.Sec. 109. Enforcement.Sec. 110. Kids online safety council.Sec. 111. Effective date.Sec. 112. Rules of construction and other matters.TITLE II—Filter Bubble TransparencySec. 201. Definitions.Sec. 202. Requirement to allow users to see unmanipulated content on internet platforms.TITLE III—Relationship to State laws; severabilitySec. 301. Relationship to State laws.Sec. 302. Severability.IKids Online Safety101.DefinitionsIn this title:(1)ChildThe term child means an individual who is under the age of 13.(2)Compulsive usageThe term compulsive usage means a persistent and repetitive use of a covered platform that significantly impacts one or more major life activities of an individual, including socializing, sleeping, eating, learning, reading, concentrating, communicating, or working.(3)Covered platform(A)In generalThe term covered platform means an online platform, online video game, messaging application, or video streaming service that connects to the internet and that is used, or is reasonably likely to be used, by a minor.(B)ExceptionsThe term covered platform does not include—(i)an entity acting in its capacity as a provider of—(I)a common carrier service subject to the Communications Act of 1934 (47 U.S.C. 151 et seq.) and all Acts amendatory thereof and supplementary thereto;(II)a broadband internet access service (as such term is defined for purposes of section 8.1(b) of title 47, Code of Federal Regulations, or any successor regulation);(III)an email service;(IV)a teleconferencing or video conferencing service that allows reception and transmission of audio or video signals for real-time communication, provided that—(aa)the service is not an online platform; and(bb)the real-time communication is initiated by using a unique link or identifier to facilitate access; or(V)a wireless messaging service, including such a service provided through short messaging service or multimedia messaging service protocols, that is not a component of, or linked to, an online platform and where the predominant or exclusive function is direct messaging consisting of the transmission of text, photos or videos that are sent by electronic means, where messages are transmitted from the sender to a recipient, and are not posted within an online platform or publicly;(ii)an organization not organized to carry on business for its own profit or that of its members;(iii)any public or private—(I)early childhood education program or preschool that provides for the care, development, and education of infants, toddlers, or young children who are not yet enrolled in kindergarten;(II)elementary school (as defined in section 8101 of the Elementary and Secondary Education Act of 1965 (20 U.S.C. 7801)) or secondary school (as so defined);(III)school providing career and technical education (as defined in section 3 of the Carl D. Perkins Career and Technical Education Act of 2006 (20 U.S.C. 2302));(IV)school providing adult education and literacy activities (as defined in section 203 of the Adult Education and Family Literacy Act (29 U.S.C. 3272)); or(V)institution of higher education (as defined in section 101, and subparagraphs (A) and (B) of section 102(a)(1), of the Higher Education Act of 1965 (20 U.S.C. 1001, 1002(a)(1)));(iv)a library (as defined in section 213 of the Library Services and Technology Act (20 U.S.C. 9122));(v)a news or sports coverage website or app where—(I)the inclusion of video content on the website or app is related to the website or app’s own gathering, reporting, or publishing of news content or sports coverage; and(II)the website or app is not otherwise an online platform;(vi)a product or service that primarily functions as business-to-business software, such as a cloud storage, file sharing, or file collaboration service;(vii)a virtual private network or similar service that exists predominantly to route internet traffic between locations; or(viii)a government entity with a .gov internet domain (as described in section 2215 of the Homeland Security Act of 2002 (6 U.S.C. 665)).(4)Design featureThe term design feature means any feature or component of a covered platform that will encourage or increase the frequency, time spent, or activity of minors on the covered platform. Design features include but are not limited to—(A)infinite scrolling or auto play;(B)rewards or incentives based on the frequency, time spent, or activity of minors on the covered platform;(C)notifications and push alerts;(D)badges or other visual award symbols based on the frequency, time spent, or activity of minors on the covered platform;(E)personalized design features;(F)in-game purchases; or(G)appearance altering filters.(5)GeolocationThe term geolocation has the meaning given the term geolocation information in section 1302 of the Children’s Online Privacy Protection Act of 1998 (15 U.S.C. 6501), as added by section 201(a).(6)Know or knowsThe term know or knows means to have actual knowledge or knowledge fairly implied on the basis of objective circumstances.(7)Microtransaction(A)In generalThe term microtransaction means a purchase made in an online video game (including a purchase made using a virtual currency that is purchasable or redeemable using cash or credit or that is included as part of a paid subscription service).(B)InclusionsSuch term includes a purchase involving surprise mechanics, new characters, or in-game items.(C)ExclusionsSuch term does not include—(i)a purchase made in an online video game using a virtual currency that is earned through gameplay and is not otherwise purchasable or redeemable using cash or credit or included as part of a paid subscription service; or(ii)a purchase of additional levels within the game or an overall expansion of the game.(8)MinorThe term minor means an individual who is under the age of 17.(9)Narcotic drugThe term narcotic drug has the meaning given such term in section 102 of the Controlled Substances Act (21 U.S.C. 802).(10)Online platform(A)In generalThe term online platform means any public-facing website, online service, online application, or mobile application that predominantly provides a community forum for user-generated content, such as sharing videos, images, games, audio files, or other content, including a social media service, social network, or virtual reality environment.(B)Incidental chat functionsA website, online service, online application, or mobile application is not an online platform solely on the basis that it includes a chat, comment, or other interactive function that is incidental to its predominant purpose.(11)Online video gameThe term online video game means a video game, including an educational video game, that connects to the internet and that allows a user to—(A)create and upload content other than content that is incidental to gameplay, such as character or level designs created by the user, preselected phrases, or short interactions with other users;(B)engage in microtransactions within the game; or(C)communicate with other users.(12)ParentThe term parent includes a legal guardian.(13)Personal dataThe term personal data has the same meaning as the term personal information as defined in section 1302 of the Children’s Online Privacy Protection Act (15 U.S.C. 6501).(14)Personalized design featureThe term personalized design feature means a fully or partially automated system, including a recommendation system, that is based on the collection of personal data of users and that encourages or increases the frequency, time spent, or activity of minors on the covered platform.(15)Personalized recommendation systemThe term personalized recommendation system means a fully or partially automated system used to suggest, promote, or rank content, including other users, hashtags, or posts, based on the personal data of users. A recommendation system that suggests, promotes, or ranks content based solely on the user’s language, city or town, or age shall not be considered a personalized recommendation system.(16)Sexual exploitation and abuseThe term sexual exploitation and abuse means any of the following:(A)Coercion and enticement, as described in section 2422 of title 18, United States Code.(B)Child sexual abuse material, as described in sections 2251, 2252, 2252A, and 2260 of title 18, United States Code.(C)Trafficking for the production of images, as described in section 2251A of title 18, United States Code.(D)Sex trafficking of children, as described in section 1591 of title 18, United States Code.(17)StateThe term State means each State of the United States, the District of Columbia, each commonwealth, territory, or possession of the United States, and each federally recognized Indian Tribe.(18)UserThe term user means, with respect to a covered platform, an individual who registers an account or creates a profile on the covered platform.102.Duty of care(a)Prevention of harm to minorsA covered platform shall exercise reasonable care in the creation and implementation of any design feature to prevent and mitigate the following harms to minors where a reasonable and prudent person would agree that such harms were reasonably foreseeable by the covered platform and would agree that the design feature is a contributing factor to such harms:(1)Eating disorders, substance use disorders, and suicidal behaviors.(2)Depressive disorders and anxiety disorders when such conditions have objectively verifiable and clinically diagnosable symptoms and are related to compulsive usage.(3)Patterns of use that indicate compulsive usage.(4)Physical violence or online harassment activity that is so severe, pervasive, or objectively offensive that it impacts a major life activity of a minor.(5)Sexual exploitation and abuse of minors.(6)Distribution, sale, or use of narcotic drugs, tobacco products, cannabis products, gambling, or alcohol.(7)Financial harms caused by unfair or deceptive acts or practices (as defined in section 5(a)(4) of the Federal Trade Commission Act (15 U.S.C. 45(a)(4))).(b)Rules of construction(1)Nothing in subsection (a) shall be construed to require a covered platform to prevent or preclude any minor from—(A)deliberately and independently searching for, or specifically requesting, content; or(B)accessing resources and information regarding the prevention or mitigation of the harms described in subsection (a).(2)Nothing in this section shall be construed to allow a government entity to enforce subsection (a) based upon the viewpoint of users expressed by or through any speech, expression, or information protected by the First Amendment to the Constitution of the United States.103.Safeguards for minors(a)Safeguards for minors(1)SafeguardsA covered platform shall provide a user or visitor that the covered platform knows is a minor with readily accessible and easy-to-use safeguards to, as applicable—(A)limit the ability of other users or visitors to communicate with the minor;(B)prevent other users or visitors, whether registered or not, from viewing the minor’s personal data collected by or shared on the covered platform, in particular restricting public access to personal data;(C)limit by default design features that encourage or increase the frequency, time spent, or activity of minors on the covered platform, such as infinite scrolling, auto playing, rewards for time spent on the platform, notifications, and other design features that result in compulsive usage of the covered platform by the minor;(D)control personalized recommendation systems, including the ability for a minor to have—(i)a prominently displayed option to opt out of such personalized recommendation systems, while still allowing the display of content based on a chronological format; and(ii)a prominently displayed option to limit types or categories of recommendations from such systems; and(E)restrict the sharing of the geolocation of the minor and provide notice regarding the tracking of the minor’s geolocation.(2)OptionA covered platform shall provide a user that the covered platform knows is a minor with a readily accessible and easy-to-use option to limit the amount of time spent by the minor on the covered platform.(3)Default safeguard settings for minorsA covered platform shall provide that, in the case of a user or visitor that the platform knows is a minor, the default setting for any safeguard described under paragraph (1) shall be the option available on the platform that provides the most protective level of control that is offered by the platform over privacy and safety for that user or visitor, unless otherwise enabled by the parent of the minor.(b)Parental tools(1)ToolsA covered platform shall provide readily accessible and easy-to-use parental tools for parents to support a user that the platform knows is a minor with respect to the use of the platform by that user.(2)RequirementsThe parental tools provided by a covered platform under paragraph (1) shall include—(A)the ability to manage a minor’s privacy and account settings, including the safeguards and options established under subsection (a), in a manner that allows parents to—(i)view the privacy and account settings; and(ii)in the case of a user that the platform knows is a child, change and control the privacy and account settings;(B)the ability to restrict purchases and financial transactions by the minor, where applicable; and(C)the ability to view metrics of total time spent on the covered platform and restrict time spent on the covered platform by the minor.(3)Notice to minorsA covered platform shall provide clear and conspicuous notice to a user when the tools described in this subsection are in effect and what settings or controls have been applied.(4)Default toolsA covered platform shall provide that, in the case of a user that the platform knows is a child, the tools required under paragraph (1) shall be enabled by default.(5)Application to existing accountsIf, prior to the effective date of this subsection, a covered platform provided a parent of a user that the platform knows is a child with notice and the ability to enable the parental tools described under this subsection in a manner that would otherwise comply with this subsection, and the parent opted out of enabling such tools, the covered platform is not required to enable such tools with respect to such user by default when this subsection takes effect.(c)Reporting mechanism(1)Reporting toolsA covered platform shall provide—(A)a readily accessible and easy-to-use means for users and visitors to submit reports to the covered platform of harms to a minor on the covered platform;(B)an electronic point of contact specific to matters involving harms to a minor; and(C)confirmation of the receipt of such a report and, within the applicable time period described in paragraph (2), a substantive response to the individual that submitted the report.(2)TimingA covered platform shall establish an internal process to receive and substantively respond to such reports in a reasonable and timely manner, but in no case later than—(A)10 days after the receipt of a report, if, for the most recent calendar year, the platform averaged more than 10,000,000 active users on a monthly basis in the United States;(B)21 days after the receipt of a report, if, for the most recent calendar year, the platform averaged less than 10,000,000 active users on a monthly basis in the United States; and(C)notwithstanding subparagraphs (A) and (B), if the report involves an imminent threat to the safety of a minor, as promptly as needed to address the reported threat to safety.(d)Advertising of illegal productsA covered platform shall not facilitate the advertising of narcotic drugs, cannabis products, tobacco products, gambling, or alcohol to an individual that the covered platform knows is a minor.(e)Rules of application(1)AccessibilityWith respect to safeguards and parental tools described under subsections (a) and (b), a covered platform shall provide—(A)information and control options in a clear and conspicuous manner that takes into consideration the differing ages, capacities, and developmental needs of the minors most likely to access the covered platform and does not encourage minors or parents to weaken or disable safeguards or parental tools;(B)readily accessible and easy-to-use controls to enable or disable safeguards or parental tools, as appropriate; and(C)information and control options in the same language, form, and manner as the covered platform provides the product or service used by minors and their parents.(2)Dark patterns prohibitionIt shall be unlawful for any covered platform to design, embed, modify, or manipulate a user interface of a covered platform with the purpose or substantial effect of obscuring, subverting or impairing user autonomy, decision-making, or choice with respect to safeguards or parental tools required under this section.(3)Timing considerations(A)No interruption to gameplaySubsections (a)(1)(C) and (b)(3) shall not require an online video game to interrupt the natural sequence of gameplay, such as progressing through game levels or finishing a competition.(B)Application of changes to offline devices or accountsIf a user’s device or user account does not have access to the internet at the time of a change to parental tools, a covered platform shall apply changes the next time the device or user is connected to the internet.(f)Device or console controls(1)In generalNothing in this section shall be construed to prohibit a covered platform from integrating its products or service with, or duplicate controls or tools provided by, third-party systems, including operating systems or gaming consoles, to meet the requirements imposed under subsections (a) and (b) relating to safeguards for minors and parental tools, provided that—(A)the controls or tools meet such requirements; and(B)the minor or parent is provided sufficient notice of the integration and use of the parental tools.(2)Preservation of protectionsIn the event of a conflict between the controls or tools of a third-party system, including operating systems or gaming consoles, and a covered platform, the covered platform is not required to override the controls or tools of a third-party system if it would undermine the protections for minors from the safeguards or parental tools imposed under subsections (a) and (b).(g)ExceptionA covered platform shall provide the safeguards and parental tools described in subsections (a) and (b) to an educational agency or institution (as defined in section 444 of the General Education Provisions Act (20 U.S.C. 1232g(a)(3))), rather than to the user or visitor, when the covered platform is acting on behalf of the educational agency or institution subject to a written contract that complies with the requirements of the Children’s Online Privacy Protection Act (15 U.S.C. 6501 et seq.) and the Family Educational Rights and Privacy Act of 1974 (20 U.S.C. 1232g).(h)Rules of constructionNothing in this section shall be construed to—(1)prevent a covered platform from taking reasonable measures to—(A)block, detect, or prevent the distribution of unlawful, obscene, or other harmful material to minors as described in section 102(a); or(B)block or filter spam, prevent criminal activity, or protect the security of a platform or service;(2)require the disclosure of the browsing behavior, search history, messages, contact list, or other content or metadata of the communications of a minor;(3)prevent a covered platform from using a personalized recommendation system to display content to a minor if the system only uses information on—(A)the language spoken by the minor;(B)the city the minor is located in; or(C)the minor’s age;(4)prevent an online video game from disclosing a username or other user identification for the purpose of competitive gameplay or to allow for the reporting of users;(5)prevent a covered platform from contracting or entering into an agreement with a third-party entity, whose primary or exclusive function is to provide the safeguards or parental tools required under subsections (a) and (b) or to offer similar or stronger protective capabilities for minors, to assist with meeting the requirements imposed under subsections (a) and (b); or(6)prevent a parent or user from authorizing a third-party entity described in subparagraph (5) to implement such safeguards or parental tools or provide similar or stronger protective capabilities for minors, at the choice of the parent or user.104.Disclosure(a)Notice(1)Registration or purchasePrior to registration or purchase of a covered platform by an individual that the platform knows is a minor, the platform shall provide clear, conspicuous, and easy-to-understand—(A)notice of the policies and practices of the covered platform with respect to safeguards for minors;(B)information about how to access the safeguards and parental tools required under section 103; and(C)notice about how to access the information on personalized recommendation systems required under subsection (b).(2)Notification(A)Notice and acknowledgmentIn the case of an individual that a covered platform knows is a child, the platform shall provide information about the parental tools and safeguards required under section 103 to a parent of the child and obtain verifiable consent (as defined in section 1302 of the Children’s Online Privacy Protection Act of 1998 (15 U.S.C. 6501)).(B)Reasonable effortA covered platform shall be deemed to have satisfied the requirement described in subparagraph (A) if the covered platform is in compliance with the requirements of the Children’s Online Privacy Protection Act of 1998 (15 U.S.C. 6501 et seq.) to use reasonable efforts (taking into consideration available technology) to provide a parent with the information described in subparagraph (A) and to obtain verifiable consent as required.(3)Consolidated noticesFor purposes of this title, a covered platform may consolidate the process for providing information under this subsection and obtaining verifiable consent or the consent of the minor involved (as applicable) as required under this subsection with the obligations of the covered platform to provide relevant notice and obtain verifiable consent under the Children’s Online Privacy Protection Act of 1998 (15 U.S.C. 6501 et seq.).(4)GuidanceThe Federal Trade Commission may issue guidance to assist covered platforms in complying with the specific notice requirements of this subsection.(b)Personalized recommendation systemA covered platform that operates a personalized recommendation system shall set out in its terms and conditions, in a clear, conspicuous, and easy-to-understand manner—(1)an overview of how each personalized recommendation system is used by the covered platform to provide information to minors, including how such systems use the personal data of minors; and(2)information about options for minors or their parents to opt out of or control the personalized recommendation system (as applicable).(c)Advertising and marketing information and labels(1)Information and labelsA covered platform shall provide clear, conspicuous, and easy-to-understand labels and information, which can be provided through a link to another web page or disclosure, to minors on advertisements regarding—(A)the name of the product, service, or brand and the subject matter of an advertisement; and(B)whether particular media displayed to the minor is an advertisement or marketing material, including disclosure of endorsements of products, services, or brands made for commercial consideration by other users of the platform.(2)GuidanceThe Federal Trade Commission may issue guidance to assist covered platforms in complying with the requirements of this subsection, including guidance about the minimum level of information and labels for the disclosures required under paragraph (1).(d)Resources for parents and minorsA covered platform shall provide to minors and parents clear, conspicuous, easy-to-understand, and comprehensive information in a prominent location, which may include a link to a web page, regarding—(1)the policies and practices of the covered platform with respect to safeguards for minors; and(2)how to access the safeguards and parental tools required under section 103.(e)Resources in additional languagesA covered platform shall ensure, to the extent practicable, that the disclosures required by this section are made available in the same language, form, and manner as the covered platform provides any product or service used by minors and their parents.105.Transparency(a)In generalSubject to subsection (b), not less frequently than once a year, a covered platform shall issue a public report that addresses the matters in subsection (c) based on an independent, third-party audit of the covered platform with a reasonable level of assurance.(b)Scope of applicationThe requirements of this section shall apply to a covered platform if—(1)for the most recent calendar year, the platform averaged more than 10,000,000 active users on a monthly basis in the United States; and(2)the platform predominantly provides a community forum for user-generated content and discussion, including sharing videos, images, games, audio files, discussion in a virtual setting, or other content, such as acting as a social media platform, virtual reality environment, or a social network service.(c)Content(1)TransparencyThe public reports required of a covered platform under this section shall include—(A)an assessment of the extent to which the platform is likely to be accessed by minors;(B)a description of the commercial interests of the covered platform being used by minors;(C)an accounting, based on the data held by the covered platform, of—(i)the number of users using the covered platform that the platform knows to be minors in the United States;(ii)the median and mean amounts of time spent on the platform by users known to be minors in the United States who have accessed the platform during the reporting year on a daily, weekly, and monthly basis; and(iii)the amount of content being accessed by users that the platform knows to be minors in the United States that is in English, and the top 5 non-English languages used by users accessing the platform in the United States;(D)an accounting of total reports received through the reporting mechanism described in section 103, disaggregated by language, including English and the top 5 non-English languages used by users accessing the platform from the United States (as identified under subparagraph (C)(iii)); and(E)an assessment of the safeguards and parental tools under section 103, representations regarding the use of the personal data of minors, and other matters regarding compliance with this title.(2)EvaluationThe public reports required under this section shall include—(A)an assessment based on aggregate data on the exercise of safeguards and parental tools described in section 103, and other competent and reliable empirical evidence;(B)a description of whether and how the covered platform uses design features that increase, sustain, or extend the use of a product or service by a minor;(C)a description of whether, how, and for what purpose the platform collects or processes categories of personal data, including how personal data is used to operate personalized recommendation systems related to minors;(D)an evaluation of the efficacy of safeguards for minors and parental tools under section 103, and any issues in delivering such safeguards and parental tools; and(E)an assessment of differences, with respect to the matters described in subparagraphs (A) through (D), across different English and non-English languages and efficacy of safeguards in those languages.(3)MitigationThe public reports required of a covered platform under this section shall include, for English and the top 5 non-English languages used by users accessing the platform from the United States (as identified under paragraph (2)(C)(iii))—(A)a description of the safeguards and parental tools available to minors and parents on the covered platform;(B)a description of the prevention and mitigation measures a covered platform may take, if any, in response to the assessments conducted under paragraph (2), including steps take to provide the most protective level of control over safety by default;(C)a description of the processes used for the creation and implementation of any design feature that will be used by minors;(D)a description and assessment of handling reports under the requirement of section 103(c), including the rate of response, timeliness, and substantiveness of responses; and(E)the status of implementing prevention and mitigation measures identified in prior assessments.(d)Reasonable inspectionIn conducting an inspection of the reasonably foreseeable risk of harm to minors under this section, an independent, third-party auditor shall—(1)take into consideration the function of personalized recommendation systems;(2)consult parents and youth experts, including youth and families with relevant past or current experience, public health and mental health nonprofit organizations, health and development organizations, and civil society with respect to the prevention of harms to minors;(3)conduct research based on experiences of minors that use the covered platform, including reports under section 103(c) and information provided by law enforcement;(4)take account of research, including research regarding design features, marketing, or product integrity, industry best practices, or outside research;(5)take into consideration indicia or inferences of age of users, in addition to any self-declared information about the age of users; and(6)take into consideration differences in risk of reasonably foreseeable harms and effectiveness of safeguards across English and non-English languages.(e)Cooperation with independent, third-Party auditTo facilitate the report required by subsection (c), a covered platform shall—(1)provide or otherwise make available to the independent third-party conducting the audit all information and material in its possession, custody, or control that is relevant to the audit;(2)provide or otherwise make available to the independent third-party conducting the audit access to all network, systems, and assets relevant to the audit; and(3)disclose all relevant facts to the independent third-party conducting the audit, and not misrepresent in any manner, expressly or by implication, any relevant fact.(f)Privacy safeguards(1)In generalIn issuing the public reports required under this section, a covered platform shall take steps to safeguard the privacy of its users, including ensuring that data is presented in a de-identified, aggregated format such that it is not reasonably linkable to any user.(2)Rule of constructionThis section shall not be construed to require the disclosure of information that will lead to material vulnerabilities for the privacy of users or the security of a covered platform’s service or create a significant risk of the violation of Federal or State law.(3)Definition of de-identifiedAs used in this subsection, the term de-identified means data that does not identify and is not linked or reasonably linkable to a device that is linked or reasonably linkable to an individual, regardless of whether the information is aggregated.(g)LocationThe public reports required under this section should be posted by a covered platform on an easy to find location on a publicly available website.106.Market research(a)Prohibition of research on
 childrenA covered platform shall not, in the case of a user or visitor that the covered platform knows is a child, conduct market or product-focused research on such child.(b)Market research on minorsA covered platform may not, in the case of a user or visitor that the online platform knows is a minor, conduct market or product-focused research on such minor, unless the covered platform obtains verifiable parental consent (as defined in section 1302 of the Children’s Online Privacy Protection Act of 1998 (15 U.S.C. 6501)) prior to conducting such research on such minor.107.Age verification study and report(a)StudyThe Secretary of Commerce, in coordination with the Federal Communications Commission and the Federal Trade Commission, shall conduct a study evaluating the most technologically feasible methods and options for developing systems to verify age at the device or operating system level.(b)ContentsSuch study shall consider—(1)the benefits of creating a device or operating system level age verification system;(2)what information may need to be collected to create this type of age verification system;(3)the accuracy of such systems and their impact or steps to improve accessibility, including for individuals with disabilities;(4)how such a system or systems could verify age while mitigating risks to user privacy and data security and safeguarding minors’ personal data, emphasizing minimizing the amount of data collected and processed by covered platforms and age verification providers for such a system;(5)the technical feasibility, including the need for potential hardware and software changes, including for devices currently in commerce and owned by consumers; and(6)the impact of different age verification systems on competition, particularly the risk of different age verification systems creating barriers to entry for small companies.(c)ReportNot later than 1 year after the date of enactment of this Act, the agencies described in subsection (a) shall submit a report containing the results of the study conducted under such subsection to the Committee on Commerce, Science, and Transportation of the Senate and the Committee on Energy and Commerce of the House of Representatives.108.Guidance(a)In generalNot later than 18 months after the date of enactment of this Act, the Federal Trade Commission shall issue guidance to—(1)provide information and examples for covered platforms and auditors regarding the following, with consideration given to differences across English and non-English languages—(A)identifying design features that encourage or increase the frequency, time spent, or activity of minors on the covered platform;(B)safeguarding minors against the possible misuse of parental tools;(C)best practices in providing minors and parents the most protective level of control over privacy and safety;(D)using indicia or inferences of age of users for assessing use of the covered platform by minors;(E)methods for evaluating the efficacy of safeguards set forth in this title; and(F)providing additional parental tool options that allow parents to address the harms described in section 102(a); and(2)outline conduct that does not have the purpose or substantial effect of subverting or impairing user autonomy, decision-making, or choice, or of causing, increasing, or encouraging compulsive usage for a minor, such as—(A)de minimis user interface changes derived from testing consumer preferences, including different styles, layouts, or text, where such changes are not done with the purpose of weakening or disabling safeguards or parental tools;(B)algorithms or data outputs outside the control of a covered platform; and(C)establishing default settings that provide enhanced privacy protection to users or otherwise enhance their autonomy and decision-making ability.(b)Guidance on knowledge standardNot later than 18 months after the date of enactment of this Act, the Federal Trade Commission shall issue guidance to provide information, including best practices and examples, for covered platforms to understand how the Commission would determine whether a covered platform had knowledge fairly implied on the basis of objective circumstances for purposes of this title.(c)Limitation on Federal Trade
 Commission guidance(1)Effect of guidanceNo guidance issued by the Federal Trade Commission with respect to this title shall—(A)confer any rights on any person, State, or locality; or(B)operate to bind the Federal Trade Commission or any court, person, State, or locality to the approach recommended in such guidance.(2)Use in enforcement actionsIn any enforcement action brought pursuant to this title, the Federal Trade Commission or a State attorney general, as applicable—(A)shall allege a violation of a provision of this title; and(B)may not base such enforcement action on, or execute a consent order based on, practices that are alleged to be inconsistent with guidance issued by the Federal Trade Commission with respect to this title, unless the practices are alleged to violate a provision of this title.For purposes of
                            enforcing this title, State attorneys general shall take into account
                            any guidance issued by the Commission under subsection
 (b).109.Enforcement(a)Enforcement by Federal Trade Commission(1)Unfair and deceptive acts or practicesA violation of this title shall be treated as a violation of a rule defining an unfair or deceptive act or practice prescribed under section 18(a)(1)(B) of the Federal Trade Commission Act (15 U.S.C. 57a(a)(1)(B)).(2)Powers of the Commission(A)In generalThe Federal Trade Commission (referred to in this section as the Commission) shall enforce this title in the same manner, by the same means, and with the same jurisdiction, powers, and duties as though all applicable terms and provisions of the Federal Trade Commission Act (15 U.S.C. 41 et seq.) were incorporated into and made a part of this title.(B)Privileges and immunitiesAny person that violates this title shall be subject to the penalties, and entitled to the privileges and immunities, provided in the Federal Trade Commission Act (15 U.S.C. 41 et seq.).(3)Authority preservedNothing in this title shall be construed to limit the authority of the Commission under any other provision of law.(b)Enforcement by State attorneys general(1)In general(A)Civil actionsIn any case in which the attorney general of a State has reason to believe that a covered platform has violated or is violating section 103, 104, or 105, the State, as parens patriae, may bring a civil action on behalf of the residents of the State in a district court of the United States or a State court of appropriate jurisdiction to—(i)enjoin any practice that violates section 103, 104, or 105;(ii)enforce compliance with section 103, 104, or 105;(iii)on behalf of residents of the State, obtain damages, restitution, or other compensation, each of which shall be distributed in accordance with State law; or(iv)obtain such other relief as the court may consider to be appropriate.(B)Notice(i)In generalBefore filing an action under subparagraph (A), the attorney general of the State involved shall provide to the Commission—(I)written notice of that action; and(II)a copy of the complaint for that action.(ii)Exemption(I)In generalClause (i) shall not apply with respect to the filing of an action by an attorney general of a State under this paragraph if the attorney general of the State determines that it is not feasible to provide the notice described in that clause before the filing of the action.(II)NotificationIn an action described in subclause (I), the attorney general of a State shall provide notice and a copy of the complaint to the Commission at the same time as the attorney general files the action.(2)Intervention(A)In generalOn receiving notice under paragraph (1)(B), the Commission shall have the right to intervene in the action that is the subject of the notice.(B)Effect of interventionIf the Commission intervenes in an action under paragraph (1), it shall have the right—(i)to remove the action to the appropriate United States district court;(ii)to be heard with respect to any matter that arises in that action; and(iii)to file a petition for appeal.(3)ConstructionFor purposes of bringing any civil action under paragraph (1), nothing in this title shall be construed to prevent an attorney general of a State from exercising the powers conferred on the attorney general by the laws of that State to—(A)conduct investigations;(B)administer oaths or affirmations; or(C)compel the attendance of witnesses or the production of documentary and other evidence.(4)Actions by the commissionIn any case in which an action is instituted by or on behalf of the Commission for violation of this title, no State may, during the pendency of that action, institute a separate action under paragraph (1) against any defendant named in the complaint in the action instituted by or on behalf of the Commission for that violation.(5)Venue; service of process(A)VenueAny action brought under paragraph (1) may be brought in—(i)the district court of the United States that meets applicable requirements relating to venue under section 1391 of title 28, United States Code; or(ii)a State court of competent jurisdiction.(B)Service of processIn an action brought under paragraph (1) in a district court of the United States, process may be served wherever defendant—(i)is an inhabitant; or(ii)may be found.(6)LimitationA violation of section 102 shall not form the basis of liability in any action brought by the attorney general of a State under a State law.110.Kids online safety council(a)EstablishmentThere is established a Kids Online Safety Council (in this section referred to as the Council).(b)DutiesThe duties of the Council shall be to provide reports to Congress with recommendations and advice on matters related to the safety of minors online. The matters to be addressed by the Council shall include—(1)identifying emerging or current risks of harms to minors associated with online platforms;(2)recommending measures and methods for assessing, preventing, and mitigating harms to minors online;(3)recommending methods and themes for conducting research regarding online harms to minors, including in English and non-English languages; and(4)recommending best practices and clear, consensus-based technical standards for transparency reports and audits, as required under this title, including methods, criteria, and scope to promote overall accountability.(c)Number and appointment of membersThe Council shall be comprised of 11 members, of whom—(1)3 members shall be appointed by the President, including—(A)the Secretary of Commerce or a designee of the Secretary; and(B)the Secretary of Health and Human Services or a designee of the Secretary;(2)2 members shall be appointed by the Speaker of the House of Representatives;(3)2 members shall be appointed by the Minority Leader of the House of Representatives;(4)2 members shall be appointed by the Majority Leader of the Senate; and(5)2 members shall be appointed by the Minority Leader of the Senate.(d)Timing of appointmentsEach of the appointments under subsection (c) shall be made not later than 180 days after the date of the enactment of this Act.(e)Terms; vacanciesEach member of the Council shall be appointed for the life of the Council, and a vacancy in the Council shall be filled in the manner in which the original appointment was made.(f)Chairperson; vice chairpersonThe Council, once it has been fully appointed, shall select its own Chair and Vice Chair.(g)ParticipationThe Council shall consist of 1 member from each of the following:(1)academic experts with specific expertise in the prevention of online harms to minors;(2)researchers with specific expertise in social media studies;(3)parents with demonstrated experience in child online safety;(4)youth representatives with demonstrated experience in child online safety;(5)educators with demonstrated experience in child online safety;(6)representatives of online platforms;(7)representatives of online video games;(8)State attorneys general or their designees acting in State or local government; and(9)representatives of communities of socially disadvantaged individuals (as defined in section 8 of the Small Business Act (15 U.S.C. 637)).(h)Reports(1)Interim reportNot later than 1 year after the date of the initial meeting of the Council, the Council shall submit to Congress an interim report that includes a detailed summary of the work of the Council and any preliminary findings of the Council.(2)Final reportNot later than 3 years after the date of the initial meeting of the Council, the Council shall submit to Congress a final report that includes—(A)a detailed statement of the findings and conclusions of the Council;(B)dissenting opinions of any member of the Council who does not support the findings and conclusions referred to in subparagraph (A); and(C)any recommendations for legislative and administrative actions to address online safety for children and prevent harms to minors.(i)TerminationThe Council shall terminate not later than 30 days after the submission of the final report required under subsection (h)(2).(j)Non-Applicability of FACAThe Kids Online Safety Council shall not be subject to chapter 10 of title 5, United States Code (commonly referred to as the Federal Advisory Committee Act).111.Effective dateExcept as otherwise provided in this title, this title shall take effect on the date that is 18 months after the date of enactment of this Act.112.Rules of construction and other matters(a)Relationship to other lawsNothing in this title shall be construed to—(1)preempt section 444 of the General Education Provisions Act (20 U.S.C. 1232g, commonly known as the Family Educational Rights and Privacy Act of 1974) or other Federal or State laws governing student privacy;(2)preempt the Children’s Online Privacy Protection Act of 1998 (15 U.S.C. 6501 et seq.) or any rule or regulation promulgated under such Act;(3)authorize any action that would conflict with section 18(h) of the Federal Trade Commission Act (15 U.S.C. 57a(h)); or(4)expand, limit the scope, or alter the meaning of section 230 of the Communications Act of 1934 (commonly known as section 230 of the Communications Decency Act of 1996) (47 U.S.C. 230).(b)Determination of fairly implied on the basis of objective
 circumstancesFor purposes of enforcing this title, in making a determination as to whether covered platform has knowledge fairly implied on the basis of objective circumstances that a specific user is a minor, the Federal Trade Commission or a State attorney general shall rely on competent and reliable evidence, taking into account the totality of the circumstances, including whether a reasonable and prudent person under the circumstances would have known that the user is a minor.(c)Protections for privacyNothing in this title, including a determination described in subsection (b), shall be construed to require—(1)the affirmative collection of any personal data with respect to the age of users that a covered platform is not already collecting in the normal course of business; or(2)a covered platform to implement an age gating or age verification functionality.(d)ComplianceNothing in this title shall be construed to restrict a covered platform’s ability to—(1)cooperate with law enforcement agencies regarding activity that the covered platform reasonably and in good faith believes may violate Federal, State, or local laws, rules, or regulations;(2)comply with a lawful civil, criminal, or regulatory inquiry, subpoena, or summons by Federal, State, local, or other government authorities;(3)investigate, establish, exercise, respond to, or defend against legal claims;(4)prevent, detect, protect against, or respond to any security incident, identity theft, fraud, harassment, malicious or deceptive activity, or any illegal activities; or(5)investigate or report those responsible for any action described in paragraph (4).(e)Application to video streaming servicesA video streaming service shall be deemed to be in compliance with this title if it predominantly consists of news, sports, entertainment, or other video programming content that is preselected by the provider and not user-generated, and—(1)any chat, comment, or interactive functionality is provided incidental to, directly related to, or dependent on provision of such content; and(2)if such video streaming service requires account owner registration and is not predominantly news or sports, the service includes the capability—(A)to limit a minor’s access to the service, which may utilize a system of age-rating;(B)to limit the automatic playing of on-demand content selected by a personalized recommendation system for an individual that the service knows is a minor;(C)for a parent to manage a minor’s privacy and account settings, and restrict purchases and financial transactions by a minor, where applicable;(D)to provide an electronic point of contact specific to matters described in this paragraph;(E)to offer a clear, conspicuous, and easy-to-understand notice of its policies and practices with respect to the capabilities described in this paragraph; and(F)when providing on-demand content, to employ measures that safeguard against serving advertising for narcotic drugs, cannabis products, tobacco products, gambling, or alcohol directly to the account or profile of an individual that the service knows is a minor.IIFilter Bubble Transparency201.DefinitionsIn this title:(1)Algorithmic ranking systemThe term algorithmic ranking system means a computational process, including one derived from algorithmic decision-making, machine learning, statistical analysis, or other data processing or artificial intelligence techniques, used to determine the selection, order, relative prioritization, or relative prominence of content from a set of information that is provided to a user on an online platform, including the ranking of search results, the provision of content recommendations, the display of social media posts, or any other method of automated content selection.(2)Approximate geolocation informationThe term approximate geolocation information means information that identifies the location of an individual, but with a precision of less than 5 miles.(3)CommissionThe term Commission means the Federal Trade Commission.(4)Connected deviceThe term connected device means an electronic device that—(A)is capable of connecting to the internet, either directly or indirectly through a network, to communicate information at the direction of an individual;(B)has computer processing capabilities for collecting, sending, receiving, or analyzing data; and(C)is primarily designed for or marketed to consumers.(5)Input-transparent algorithm(A)In generalThe term input-transparent algorithm means an algorithmic ranking system that does not use the user-specific data of a user to determine the selection, order, relative prioritization, or relative prominence of information that is furnished to such user on an online platform, unless the user-specific data is expressly provided to the platform by the user for such purpose.(B)Data expressly provided to the platformFor purposes of subparagraph (A), user-specific data that is provided by a user for the express purpose of determining the selection, order, relative prioritization, or relative prominence of information that is furnished to such user on an online platform—(i)includes user-supplied search terms, filters, speech patterns (if provided for the purpose of enabling the platform to accept spoken input or selecting the language in which the user interacts with the platform), saved preferences, the resumption of a previous search, and the current precise geolocation information that is supplied by the user;(ii)includes the user’s current approximate geolocation information;(iii)includes data submitted to the platform by the user that expresses the user’s desire to receive particular information, such as the social media profiles the user follows, the video channels the user subscribes to, or other content or sources of content on the platform the user has selected;(iv)does not include the history of the connected device of the user, including the history of web searches and browsing, previous geographical locations, physical activity, device interaction, and financial transactions of the user; and(v)does not include inferences about the user or the connected device of the user, without regard to whether such inferences are based on data described in clause (i) or (iii).(6)Online platform(A)In generalSubject to subparagraph (B), the term online platform means any public-facing website, online service, online application, or mobile application that predominantly provides a community forum for user-generated content, such as sharing videos, images, games, audio files, or other content, including a social media service, social network, or virtual reality environment.(B)Scope(i)Incidental chat functionsA website, online service, online application, or mobile application is not an online platform solely on the basis that it includes a chat, comment, or other interactive function that is incidental to its predominant purpose.(ii)Review sitesA website, online service, online application, or mobile application that has the predominant purpose of providing travel reviews is not an online platform.(7)Opaque algorithmThe term opaque algorithm—(A)means an algorithmic ranking system that determines the selection, order, relative prioritization, or relative prominence of information that is furnished to such user on an online platform based, in whole or part, on user-specific data that was not expressly provided by the user to the platform for such purpose; and(B)does not include an algorithmic ranking system used by an online platform if—(i)the only user-specific data (including inferences about the user) that the system uses is information relating to the age of the user; and(ii)such information is only used to restrict the access of a user to content on the basis that the individual is not old enough to access such content.(8)Precise geolocation informationThe term precise geolocation information means geolocation information that identifies the location of an individual to within a range of 5 miles or less.(9)User-specific dataThe term user-specific data means information relating to an individual or a specific connected device that would not necessarily be true of every individual or device.202.Requirement to allow users to see unmanipulated content on internet
 platforms(a)In generalBeginning on the date that is 1 year after the date of enactment of this Act, it shall be unlawful for any person to operate an online platform that uses an opaque algorithm unless the person complies with the requirements of subsection (b).(b)Opaque algorithm requirements(1)In generalThe requirements of this subsection with respect to a person that operates an online platform that uses an opaque algorithm are the following:(A)The person provides users of the platform with the following notices:(i)Notice that the platform uses an opaque algorithm that uses user-specific data to select the content the user sees. Such notice shall be presented in a clear and conspicuous manner on the platform whenever the user interacts with an opaque algorithm for the first time, and may be a one-time notice that can be dismissed by the user.(ii)Notice, to be included in the terms and conditions of the online platform, in a clear, accessible, and easily comprehensible manner that is to be updated whenever the online platform makes a material change, of—(I)the most salient features, inputs, and parameters used by the algorithm;(II)how any user-specific data used by the algorithm is collected or inferred about a user of the platform, and the categories of such data;(III)any options that the online platform makes available for a user of the platform to opt out or exercise options under subparagraph (B), modify the profile of the user or to influence the features, inputs, or parameters used by the algorithm; and(IV)any quantities, such as time spent using a product or specific measures of engagement or social interaction, that the algorithm is designed to optimize, as well as a general description of the relative importance of each quantity for such ranking.(B)The online platform enables users to easily switch between the opaque algorithm and an input-transparent algorithm in their use of the platform.(2)Rule of constructionNothing in this subsection shall be construed to require an online platform to disclose any information, including data or algorithms—(A)relating to a trade secret or other protected intellectual property;(B)that is confidential business information; or(C)that is privileged.(3)Prohibition on differential pricingAn online platform shall not deny, charge different prices or rates for, or condition the provision of a service or product to a user based on the user’s election to use an input-transparent algorithm in their use of the platform, as provided under paragraph (1)(B).(4)Special ruleNotwithstanding paragraphs (1) and (2), an online platform shall provide the notice and opt-out described in paragraphs (1) and (2) to the educational agency or institution (as defined in section 444(a)(3) of the General Education Provisions Act (20 U.S.C. 1232g(a)(3)), rather than to the user, when the online platform is acting on behalf of an educational agency or institution (as so defined), subject to a written contract that complies with the requirements of the Children’s Online Privacy Protection Act of 1998 (15 U.S.C. 1232g(a)(3)) and section 444 of the General Education Provisions Act (20 U.S.C. 1232g) (commonly known as the Family Educational Rights and Privacy Act of 1974).(c)Enforcement by Federal Trade Commission(1)Unfair or deceptive acts or practicesA violation of this section by an operator of an online platform shall be treated as a violation of a rule defining an unfair or deceptive act or practice prescribed under section 18(a)(1)(B) of the Federal Trade Commission Act (15 U.S.C. 57a(a)(1)(B)).(2)Powers of commission(A)In generalThe Federal Trade Commission shall enforce this section in the same manner, by the same means, and with the same jurisdiction, powers, and duties as though all applicable terms and provisions of the Federal Trade Commission Act (15 U.S.C. 41 et seq.) were incorporated into and made a part of this section.(B)Privileges and immunitiesAny person who violates this section shall be subject to the penalties and entitled to the privileges and immunities provided in the Federal Trade Commission Act (15 U.S.C. 41 et seq.).(C)Authority preservedNothing in this section shall be construed to limit the authority of the Commission under any other provision of law.(d)Rule of construction To preserve personalized blocksNothing in this section shall be construed to limit or prohibit an online platform’s ability to, at the direction of an individual user or group of users, restrict another user from searching for, finding, accessing, or interacting with such user’s or group’s account, content, data, or online community.IIIRelationship to State laws; severability301.Relationship to State lawsThe provisions of this Act shall preempt any State law, rule, or regulation only to the extent that such State law, rule, or regulation conflicts with a provision of this Act. Nothing in this Act shall be construed to prohibit a State from enacting a law, rule, or regulation that provides greater protection to minors than the protection provided by the provisions of this Act.302.SeverabilityIf any provision of this Act, or an amendment made by this Act, is determined to be unenforceable or invalid, the remaining provisions of this Act and the amendments made by this Act shall not be affected.